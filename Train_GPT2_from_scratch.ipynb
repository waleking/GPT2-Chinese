{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所需环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformers版本号为2.1.1，pytorch为1.2.0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 15:24:11.910086 140436257081152 file_utils.py:39] PyTorch version 1.2.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在requirments.txt中，列出了所需要的其他的包，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==2.1.1\n",
      "torch\n",
      "numpy\n",
      "tqdm\n",
      "sklearn\n",
      "keras\n",
      "tb-nightly\n",
      "future\n",
      "thulac\n"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录结构以及重要文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前文件夹中包含的文件如下。其中**doupo**文件夹下包含“斗破苍穹”的示例任务，用以简单说明如何构建字典、tokenization、以及在一个小文件上从头训练一个指定层数的GPT模型；**pretrain**文件夹下包含预训练任务，主要用以说明如何在260万篇新闻文档上预训练一个12层的GPT2；**dataaugmentation**文件夹下包含数据增强任务，主要用以说明如何利用预训练的GPT2模型在较小的文档集上进行微调，并用于数据增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├── cache\n",
      "├── config\n",
      "├── dataaugmentation\n",
      "├── eval.py\n",
      "├── generate.py\n",
      "├── generate_texts.py\n",
      "├── LICENSE\n",
      "├── pretrain\n",
      "├── README.md\n",
      "├── requirements.txt\n",
      "├── sample\n",
      "├── tasks\n",
      "├── tokenizations\n",
      "├── Train_GPT2_from_scratch.ipynb\n",
      "├── train.json\n",
      "├── train_on_small_file.py\n",
      "└── train_single.py\n",
      "\n",
      "7 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree -L 1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要重点加以说明的是，上述列表中的tokenizations文件夹，train_single.py, 和train_on_small_file.py。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizations`提供了各种tokenization的方法，具体到本代码库中，使用的是该文件夹中的`tokenization_chars.py`文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization的第一阶段是将纯文本文件依照字典文件vocab.txt进行划分为token，第二阶段是将token转化为字典文件中token对应的数字。举例来说，\"[CLS]《斗破苍穹》天蚕土豆[SEP][CLS] ...\"在第一阶段被分割为列表：['[CLS]', '《', '斗', '破', '苍', '穹', '》', '天', '蚕', '土', '豆', '[SEP]', '[CLS]', ...]，其中[CLS], [SEP]在vocab.txt对应一个单独的占位符；第二阶段在查找vocab.txt之后，将字符串列表转化为整型数列表：101 517 3159 4788 5721 4957 518 1921 6014 1759 6486 102 101。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下是tokenization第一阶段的代码，输入为text字符串，输出为字符串列表result，对于形如[.\\*]的特殊字符使用栈来处理：如果该特殊字符出现在vocab.txt中，则被提取为一个单独的字符串存入列表中，如161行所示；反之若没有出现在vocab.txt中，则逐字符加入到列表中，如163-165行所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140     def _tokenize(self, text):\n",
      "141         #pdb.set_trace()\n",
      "142         stack = []\n",
      "143 \n",
      "144         result = []\n",
      "145         i = 0\n",
      "146         len_txt = len(text)\n",
      "147         while(i<len_txt):\n",
      "148             char = text[i]\n",
      "149             if(len(stack)==0):\n",
      "150                 if(char != '['):\n",
      "151                     result.append(char)\n",
      "152                 else:\n",
      "153                     stack.append('[')\n",
      "154             else:\n",
      "155                 if(char == ']'):\n",
      "156                     stack.append(char) # don't forget to append it firstly\n",
      "157                     # process the content in the stack\n",
      "158                     seq = \"\".join(stack)\n",
      "159                     if(seq in self.vocab):\n",
      "160                         # the [.*] stuff appeared in the vocabulary, e.g. [UNK], [CLS], [SEP], ...\n",
      "161                         result.append(seq)\n",
      "162                     else:\n",
      "163                         # other [.*] stuff which are not valid element in the vocabulary\n",
      "164                         for e in stack:\n",
      "165                             result.append(e)\n",
      "166                     # clean the stack after processing \n",
      "167                     stack = []    \n",
      "168                 else:\n",
      "169                     stack.append(char)\n",
      "170             i += 1\n",
      "171 \n",
      "172         if(len(stack)>0): \n",
      "173             for e in stack:\n",
      "174                 result.append(e)\n",
      "175         # pdb.set_trace()\n",
      "176         return result\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=140 and $.<=176)' tokenizations/tokenization_chars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization的第二部分如下所示，对第一阶段获得的result列表中的token字符串进行查表操作，如果没有出现在vocab.txt中，那么就以[UNK]对应的id来代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178     def _convert_token_to_id(self, token):\n",
      "179         \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
      "180         #if(token not in self.vocab):\n",
      "181         #    print(token)\n",
      "182         return self.vocab.get(token, self.vocab.get(self.unk_token))\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=178 and $.<=182)' tokenizations/tokenization_chars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，本代码库中的tokenization方法主要为中文设计，如果训练数据中混杂有英文字符，那么就将英文单词按照char level进行划分，例如\"word\"会被\"w\",\"o\",\"r\",\"d\"四个字符来代替。不同于BPE的方法，我们认为这样处理是最节省计算资源的，比起BPE能够更从容应对几十GB的中文训练语料。从具体的实际效果来看，在斗破苍穹的语料上进行tokenization，普通方法需要耗时77.9秒，使用了我们的方法之后，耗时12.1秒，用时为原来的15%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两种训练方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_single.py`：当输入的训练数据为一篇完整的长文档（例如小说）或是一个单一的大型文档，此时使用`train_single.py`。有两方面的原因。（1）train_single.py在训练过程中不对training samples进行random shuffle，保持training samples之间的顺序，因此完整的长文档使用train_single.py。（2）对顺序无关的超多的样本，例如包含260万篇新闻的大型训练集，在训练过程中进行random shuffle的代价是巨大的，包括shuffle的代价，重新划分training sample的代价和tokenization的代价，并且在大型训练集上我们进行预训练的轮数有限，1到2轮就能获得一个较好的预训练模型。综合考虑shuffle的代价和收益，因此也将大型训练集中的多个样本拼接为一个单一的大型文档，使用train_single.py。我们在《从头训练一个GPT2模型》一节对此进行更详细的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_on_small_file.py`：当输入的训练数据为多个样本，并且这多个样本的总体积较小时，将这些样本汇总到一个文件，每个样本占据一行，然后使用`train_on_small_file.py`。有如下两方面原因：（1）train_on_small_file.py针对每个样本建立一个单独的training sample送入Transformer Encoder中，如果一个样本的长度不足Transformer Encoder的长度（在本代码库中用n_ctx表示），那么不足部分以\\[PAD\\]来补足；超出n_ctx的部分直接截断丢弃不用。这一点和train_single.py不同，train_single.py中多个较短的样本可能会占据一个Transformer Encoder的输入长度（n_ctx）。（2）train_on_small_file.py会在不同的训练轮次中，对training samples进行random shuffle，以提高训练质量。由于train_on_small_file.py的训练数据体积较小，样本数也较小，并且样本之间相互独立。所以，如果是唐诗、宋词、现代诗、意图增强等文本数据，由于其规模较小，完全可以使用`train_on_small_file.py`来完成训练或者微调，这样得到的模型质量要高于`train_single.py`训练得到的模型。我们在《微调GPT2模型进行数据增强》一节对此进行更详细的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从头训练一个GPT2模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处我们使用一个规模较小的文件用以验证从头训练一个GPT2模型的可行性。该文件为斗破苍穹小说文本文件，规模为16MB，16万行。如下是该文件的一些基本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 weijing weijing 16M Apr  5 10:54 rawdata/train_raw.txt\n",
      "162111 rawdata/train_raw.txt\n",
      "《斗破苍穹》天蚕土豆\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\n",
      "在线阅读：http://www.shuyaya.com/read/18/\n",
      "--------------------------------------------------\n",
      "\n",
      "第一章 陨落的天才\n",
      "\n",
      "    “斗之力，三段！”\n",
      "\n",
      "    望着测验魔石碑上面闪亮得甚至有些刺眼的五个大字，少年面无表情，唇角有着一抹自嘲，紧握的手掌，因为大力，而导致略微尖锐的指甲深深的刺进了掌心之中，带来一阵阵钻心的疼痛…\n",
      "\n",
      "    “萧炎，斗之力，三段！级别：低级！”测验魔石碑之旁，一位中年男子，看了一眼碑上所显示出来的信息，语气漠然的将之公布了出来…\n",
      "\n",
      "    中年男子话刚刚脱口，便是不出意外的在人头汹涌的广场上带起了一阵嘲讽的骚动。\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; ls -laht rawdata/train_raw.txt; wc -l rawdata/train_raw.txt; head -n 15 rawdata/train_raw.txt; echo \"...\"; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没有rawdata/train_raw.txt文件，那么运行`!cd tasks/doupo; bash train.sh`，该脚本帮助建立对应文件夹并下载train_raw.txt。如下是train.sh的部分信息。首先创建raw_data文件夹，divide文件夹，tokenized文件夹，model文件夹和config文件夹。其中，raw_data文件夹用于存储原始的训练数据和进行基本预处理之后的训练数据；divide文件夹用于存储分割后的大文件（在train_single.py中有体现）；tokenized文件夹用于存储token转为数字id之后的文件；model文件夹用于储存训练好的模型；config文件夹用于储存模型的基本配置信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tasks/doupo/train.sh`的第26行用于从公网下载原始训练数据并存储到rawdata文件夹下的train_raw.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 job_dir=\"tasks/doupo\"\n",
      "2 \n",
      "3 cd ../..\n",
      "4 \n",
      "5 if [ ! -e $job_dir/rawdata ]; then\n",
      "6     mkdir $job_dir/rawdata\n",
      "7 fi\n",
      "8 \n",
      "9 if [ ! -e $job_dir/divide ]; then\n",
      "10     mkdir $job_dir/divide\n",
      "11 fi\n",
      "12 \n",
      "13 if [ ! -e $job_dir/tokenized ]; then\n",
      "14     mkdir $job_dir/tokenized\n",
      "15 fi\n",
      "16 \n",
      "17 if [ ! -e $job_dir/model ]; then\n",
      "18     mkdir $job_dir/model\n",
      "19 fi\n",
      "20 \n",
      "21 if [ ! -e $job_dir/config ]; then\n",
      "22     mkdir $job_dir/config\n",
      "23 fi\n",
      "24 \n",
      "25 if [ ! -e $job_dir/rawdata/train.txt ]; then\n",
      "26     wget -c -O $job_dir/rawdata/train_raw.txt https://github.com/GaoPeng97/transformer-xl-chinese/blob/master/data/doupo/train.txt?raw=true\n",
      "27     # remove empty lines\n",
      "28     python $job_dir/format_raw_txt.py $job_dir/rawdata/train_raw.txt $job_dir/rawdata/train.txt \n",
      "29 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=1 and $.<=29)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tasks/doupo/train.sh`的第28行调用`format_raw_txt.py`，用于移除原始文件中的空行和去除一行中左侧多余的空格(lstrip)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t'''\n",
      "     2\tThis script is used to remove empty lines in the input file \n",
      "     3\t'''\n",
      "     4\timport sys\n",
      "     5\t\n",
      "     6\tdef format(in_filename, out_filename):\n",
      "     7\t    with open(out_filename, \"w\") as fOut:\n",
      "     8\t        with open(in_filename, \"r\") as fIn:\n",
      "     9\t            for line in fIn:\n",
      "    10\t                if(line!=\"\"):\n",
      "    11\t                    fOut.write(line.lstrip())\n",
      "    12\t\n",
      "    13\t\n",
      "    14\tdef test():\n",
      "    15\t    in_filename=\"./rawdata/train_raw.txt\"\n",
      "    16\t    out_filename=\"./rawdata/train.txt\"\n",
      "    17\t    format(in_filename, out_filename)\n",
      "    18\t\n",
      "    19\t\n",
      "    20\tif __name__==\"__main__\":\n",
      "    21\t    if(len(sys.argv)<3):\n",
      "    22\t        print(\"usage: python format_raw_txt.py in_filename out_filename\")\n",
      "    23\t    else:\n",
      "    24\t        in_filename = sys.argv[1]\n",
      "    25\t        out_filename = sys.argv[2]\n",
      "    26\t        format(in_filename, out_filename)\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; cat -n format_raw_txt.py; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前多个模型都直接使用了BERT chinese字表，该字表拥有字符21128个。但是该字表有如下的问题：不包含大写字母A到Z，不包含制表符，空格等字符。我们可以将这些字符追加到BERT chinese字表之后，如`train.sh`代码中的第31行到44行所示，将新的字符表保存在doupo/config/vocab.txt文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 vocab_size=21128\n",
      "32 declare -a additional_chars=(\"“\" \"”\" \"…\" \"’\" \"‘\" \"—\" \" \" \"\\t\" \"\\`\")\n",
      "33 new_vocab_size=$(($vocab_size+${#additional_chars[@]}+26))\n",
      "34 echo 'setting config/vocab.txt and config/model_config.json'\n",
      "35 if [ ! -e $job_dir/config/vocab.txt ]; then\n",
      "36     wget -c -O $job_dir/config/vocab.txt https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt\n",
      "37     # append new characters to the vocabulary\n",
      "38     for letter in \"${additional_chars[@]}\"; do\n",
      "39         echo -e \"$letter\" >> $job_dir/config/vocab.txt\n",
      "40     done\n",
      "41     for letter in {A..Z} ; do\n",
      "42         echo $letter >> $job_dir/config/vocab.txt\n",
      "43     done\n",
      "44 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=31 and $.<=44)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以进一步的设置模型参数，并将模型参数保存于config/model_config.json。如果不存在doupo/config/model_config.json，那么doupo/train.sh的第49行拷贝config/model_config.json模板到指定位置，并进行编辑。如下的代码第52，54，56，57行用于编辑模型参数，例如将层数修改为10层，将n_ctx和n_positions从1024修改为512。因为n_ctx是Transformer Encoder能够容纳的最大序列长度，因此减半之后可以大幅度节省训练时占用的显存，同时也考虑到512是一个合理的较长的长度，能够较大限度的捕获文本上远距离的依赖关系。此外我们将stride设置为256，也就是在一个长序列上窗口大小为512，每次移动窗口的幅度为256。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 stride=256\n",
      "47 n_layers=10\n",
      "48 n_ctx=512\n",
      "49 if [ ! -e $job_dir/config/model_config.json ]; then\n",
      "50     cp config/model_config.json $job_dir/config/model_config.json\n",
      "51     # change vocabulary size\n",
      "52     perl -pi -e 's/'$vocab_size'/'$new_vocab_size'/g' $job_dir/config/model_config.json\n",
      "53     # change the number of layers from 12 to $n_layers\n",
      "54     perl -pi -e 's/\"n_layer\": 12/\"n_layer\": '$n_layers'/g' $job_dir/config/model_config.json\n",
      "55     # change the model input length from 1024 to $n_ctx\n",
      "56     perl -pi -e 's/\"n_ctx\": 1024/\"n_ctx\": '$n_ctx'/g' $job_dir/config/model_config.json\n",
      "57     perl -pi -e 's/\"n_positions\": 1024/\"n_positions\": '$n_ctx'/g' $job_dir/config/model_config.json\n",
      "58 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=46 and $.<=58)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以在`config/model_config.json`中查看即将要训练的模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t{\n",
      "     2\t  \"initializer_range\": 0.02,\n",
      "     3\t  \"layer_norm_epsilon\": 1e-05,\n",
      "     4\t  \"n_ctx\": 512,\n",
      "     5\t  \"n_embd\": 768,\n",
      "     6\t  \"n_head\": 12,\n",
      "     7\t  \"n_layer\": 10,\n",
      "     8\t  \"n_positions\": 512,\n",
      "     9\t  \"vocab_size\": 21163\n",
      "    10\t}"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; cat -n config/model_config.json; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要的数据预处理发生于`train_single.py`的`build_files`文件中，如下所示。`build_files`包含有多个参数，其中有必要说明的是`num_pieces`和`full_tokenizer`。`full_tokenizer`调用的是《Tokenization》一小节中提到的两阶段方法，效率较高。`num_pieces`将一个大文件分割为若干个小文件，以减小训练时IO一个大文件带来的内存压力。\n",
    "如下，第26行到第35行用以分割大文件到divide文件夹。分割之后，每一行补充[CLS]字符，回车符'\\\\n'转为[SEP]字符，然后调用`full_tokenizer`将token转为id。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例来说，\"《斗破苍穹》天蚕土豆\"这一行转为\"[CLS]《斗破苍穹》天蚕土豆[SEP]\"并转为对应的数字id。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 def build_files(raw_data_path, divide_path, tokenized_data_path, full_tokenizer, num_pieces):\n",
      "19     if not os.path.exists(tokenized_data_path):\n",
      "20         os.mkdir(tokenized_data_path)\n",
      "21     if not os.path.exists(divide_path):\n",
      "22         os.mkdir(divide_path)\n",
      "23     print(\"now time: \", datetime.now())\n",
      "24     print(\"begin to divide raw text ...\")\n",
      "25 \n",
      "26     writers = [open(divide_path + 'divide_piece_{}.txt'.format(i), 'w') for i in range(0,num_pieces)]\n",
      "27 \n",
      "28     with open(raw_data_path, 'r', encoding='utf8') as f:\n",
      "29         line_num = 0\n",
      "30         for line in f:\n",
      "31             writers[line_num % num_pieces].write(\"%s\" % line)\n",
      "32             line_num += 1\n",
      "33     \n",
      "34     for i in range(0, num_pieces):\n",
      "35         writers[i].close()\n",
      "36     \n",
      "37     print('now time: ', datetime.now())\n",
      "38     print(\"begin making tokenization ...\")\n",
      "39     files = [filename for filename in os.listdir(divide_path) if f!='.gitignore']\n",
      "40     for i, filename in enumerate(files):\n",
      "41         if(os.path.isdir(filename)):\n",
      "42             continue\n",
      "43 \n",
      "44         with open(divide_path+filename, 'r', encoding='utf8') as reader:\n",
      "45             print(\"reading file {}, now time is {}\".format(filename, datetime.now()))\n",
      "46             lines = []\n",
      "47             for line in reader:\n",
      "48                 line = line.replace('\\n', '[SEP]')\n",
      "49                 line = '[CLS]' + line\n",
      "50                 lines.append(line)\n",
      "51             \n",
      "52             single_file = ''.join(lines)\n",
      "53             single_ids = full_tokenizer.convert_tokens_to_ids(full_tokenizer._tokenize(single_file))\n",
      "54             # pdb.set_trace()\n",
      "55             with open(tokenized_data_path + 'tokenized_train_{}.txt'.format(i), 'w') as f:\n",
      "56                 for id in single_ids[:-1]:\n",
      "57                     f.write(str(id) + ' ')\n",
      "58                 f.write(str(single_ids[-1]))\n",
      "59                 f.write('\\n')\n",
      "60         print('now time: {}, tokenized tokenized_train_{}.txt'.format(datetime.now(), i))\n",
      "61 \n",
      "62     print('finish')\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=18 and $.<=62)' train_single.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 确定训练过程中的其他参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在确定模型参数之后，再定义训练过程中的其他参数，如下为`tasks/doupo/train.sh`中该部分代码，这些参数包括：迭代的轮数`epochs`，训练时的`batch_size`，每隔多少轮输出一次NLL的`log_step`，以及使用哪些显卡的`device`。考虑到具体的硬件资源，此处使用两块显卡——0号和1号，以及设置batch size为32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 raw_data_path=$job_dir/rawdata/train.txt\n",
      "61 tokenizer_path=$job_dir/config/vocab.txt\n",
      "62 tokenized_data_path=$job_dir/tokenized/\n",
      "63 divide_path=$job_dir/divide/\n",
      "64 model_config=$job_dir/config/model_config.json\n",
      "65 epochs=30\n",
      "66 batch_size=32\n",
      "67 log_step=100\n",
      "68 output_dir=$job_dir/model/\n",
      "69 num_pieces=1\n",
      "70 \n",
      "71 if [ ! -e $job_dir/tokenized/tokenized_train_0.txt ]; then\n",
      "72     # tokenization then run the training\n",
      "73     python train_single.py \\\n",
      "74         --raw_data_path $raw_data_path \\\n",
      "75         --tokenizer_path $tokenizer_path \\\n",
      "76         --tokenized_data_path $tokenized_data_path \\\n",
      "77         --divide_path $divide_path \\\n",
      "78         --model_config $model_config \\\n",
      "79         --epochs $epochs \\\n",
      "80         --batch_size $batch_size \\\n",
      "81         --stride $stride \\\n",
      "82         --log_step $log_step \\\n",
      "83         --output_dir $output_dir \\\n",
      "84         --num_pieces $num_pieces \\\n",
      "85         --raw \\\n",
      "86         --ignore_intermediate_epoch_model\n",
      "87 else\n",
      "88     # run the training on the tokenized files\n",
      "89     python train_single.py \\\n",
      "90         --raw_data_path $raw_data_path \\\n",
      "91         --tokenizer_path $tokenizer_path \\\n",
      "92         --tokenized_data_path $tokenized_data_path \\\n",
      "93         --divide_path $divide_path \\\n",
      "94         --model_config $model_config \\\n",
      "95         --epochs $epochs \\\n",
      "96         --batch_size $batch_size \\\n",
      "97         --stride $stride \\\n",
      "98         --log_step $log_step \\\n",
      "99         --output_dir $output_dir \\\n",
      "100         --num_pieces $num_pieces \\\n",
      "101         --device 0,1 \\\n",
      "102         --ignore_intermediate_epoch_model\n",
      "103 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=60 and $.<=103)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定完毕模型参数和训练过程中的其他参数之后，可以进入到tasks/doupo文件夹，然后运行train.sh。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting config/vocab.txt and config/model_config.json\n",
      "I0416 01:14:42.333565 140639139563328 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "args:\n",
      "Namespace(batch_size=32, device='0,1', divide_path='tasks/doupo/divide/', epochs=30, fp16=False, fp16_opt_level='O1', gradient_accumulation=1, ignore_intermediate_epoch_model=True, log_step=100, lr=0.00015, max_grad_norm=1.0, model_config='tasks/doupo/config/model_config.json', num_pieces=1, output_dir='tasks/doupo/model/', pretrained_model='', raw=False, raw_data_path='tasks/doupo/rawdata/train.txt', segment=False, stride=256, tokenized_data_path='tasks/doupo/tokenized/', tokenizer_path='tasks/doupo/config/vocab.txt', warmup_steps=2000)\n",
      "config:\n",
      "{\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "using device: cuda\n",
      "calculating total steps\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "total steps = 19625\n",
      "Let's use 2 GPUs!\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:26: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "starting training\n",
      "epoch 1\n",
      "time: 2020-04-16 01:14:48.601299\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "now time: 1:17. Step 100 of piece 0 of epoch 1, loss 9.202316961288453\n",
      "now time: 1:19. Step 200 of piece 0 of epoch 1, loss 7.707304573059082\n",
      "now time: 1:21. Step 300 of piece 0 of epoch 1, loss 6.231863975524902\n",
      "now time: 1:24. Step 400 of piece 0 of epoch 1, loss 5.415362277030945\n",
      "now time: 1:26. Step 500 of piece 0 of epoch 1, loss 4.971680083274841\n",
      "now time: 1:28. Step 600 of piece 0 of epoch 1, loss 4.667091364860535\n",
      "epoch 2\n",
      "time: 2020-04-16 01:30:03.152946\n",
      "now time: 1:32. Step 100 of piece 0 of epoch 2, loss 6.789287486076355\n",
      "now time: 1:34. Step 200 of piece 0 of epoch 2, loss 4.226721558570862\n",
      "now time: 1:37. Step 300 of piece 0 of epoch 2, loss 4.118758888244629\n",
      "now time: 1:39. Step 400 of piece 0 of epoch 2, loss 4.030298998355866\n",
      "now time: 1:41. Step 500 of piece 0 of epoch 2, loss 3.9456340169906614\n",
      "now time: 1:44. Step 600 of piece 0 of epoch 2, loss 3.8575130224227907\n",
      "epoch 3\n",
      "time: 2020-04-16 01:45:20.002546\n",
      "now time: 1:47. Step 100 of piece 0 of epoch 3, loss 5.745515451431275\n",
      "now time: 1:50. Step 200 of piece 0 of epoch 3, loss 3.6111994218826293\n",
      "now time: 1:52. Step 300 of piece 0 of epoch 3, loss 3.532945084571838\n",
      "now time: 1:54. Step 400 of piece 0 of epoch 3, loss 3.4371526789665223\n",
      "now time: 1:57. Step 500 of piece 0 of epoch 3, loss 3.349661066532135\n",
      "now time: 1:59. Step 600 of piece 0 of epoch 3, loss 3.2717025208473207\n",
      "epoch 4\n",
      "time: 2020-04-16 02:00:35.686268\n",
      "now time: 2:2. Step 100 of piece 0 of epoch 4, loss 4.848652067184449\n",
      "now time: 2:5. Step 200 of piece 0 of epoch 4, loss 3.0546720480918883\n",
      "now time: 2:7. Step 300 of piece 0 of epoch 4, loss 2.9983620500564574\n",
      "now time: 2:9. Step 400 of piece 0 of epoch 4, loss 2.9415189242362976\n",
      "now time: 2:12. Step 500 of piece 0 of epoch 4, loss 2.8896154952049256\n",
      "now time: 2:14. Step 600 of piece 0 of epoch 4, loss 2.853637628555298\n",
      "epoch 5\n",
      "time: 2020-04-16 02:15:52.982696\n",
      "now time: 2:18. Step 100 of piece 0 of epoch 5, loss 4.237938556671143\n",
      "now time: 2:20. Step 200 of piece 0 of epoch 5, loss 2.69880491733551\n",
      "now time: 2:22. Step 300 of piece 0 of epoch 5, loss 2.6723411226272584\n",
      "now time: 2:25. Step 400 of piece 0 of epoch 5, loss 2.6393399143218996\n",
      "now time: 2:27. Step 500 of piece 0 of epoch 5, loss 2.61063467502594\n",
      "now time: 2:29. Step 600 of piece 0 of epoch 5, loss 2.590463788509369\n",
      "epoch 6\n",
      "time: 2020-04-16 02:31:08.000836\n",
      "now time: 2:33. Step 100 of piece 0 of epoch 6, loss 3.8711335635185242\n",
      "now time: 2:35. Step 200 of piece 0 of epoch 6, loss 2.4737066078186034\n",
      "now time: 2:38. Step 300 of piece 0 of epoch 6, loss 2.4557159829139708\n",
      "now time: 2:40. Step 400 of piece 0 of epoch 6, loss 2.4382388758659364\n",
      "now time: 2:42. Step 500 of piece 0 of epoch 6, loss 2.421723482608795\n",
      "now time: 2:45. Step 600 of piece 0 of epoch 6, loss 2.3982063722610474\n",
      "epoch 7\n",
      "time: 2020-04-16 02:46:22.395491\n",
      "now time: 2:48. Step 100 of piece 0 of epoch 7, loss 3.5847596406936644\n",
      "now time: 2:51. Step 200 of piece 0 of epoch 7, loss 2.2856746673583985\n",
      "now time: 2:53. Step 300 of piece 0 of epoch 7, loss 2.2785504913330077\n",
      "now time: 2:55. Step 400 of piece 0 of epoch 7, loss 2.2767979526519775\n",
      "now time: 2:58. Step 500 of piece 0 of epoch 7, loss 2.2672856426239014\n",
      "now time: 3:0. Step 600 of piece 0 of epoch 7, loss 2.2545839881896974\n",
      "epoch 8\n",
      "time: 2020-04-16 03:01:38.067122\n",
      "now time: 3:3. Step 100 of piece 0 of epoch 8, loss 3.352515172958374\n",
      "now time: 3:6. Step 200 of piece 0 of epoch 8, loss 2.1405993843078615\n",
      "now time: 3:8. Step 300 of piece 0 of epoch 8, loss 2.1453472924232484\n",
      "now time: 3:10. Step 400 of piece 0 of epoch 8, loss 2.1394610095024107\n",
      "now time: 3:13. Step 500 of piece 0 of epoch 8, loss 2.124991798400879\n",
      "now time: 3:15. Step 600 of piece 0 of epoch 8, loss 2.1123932445049287\n",
      "epoch 9\n",
      "time: 2020-04-16 03:16:51.998176\n",
      "now time: 3:19. Step 100 of piece 0 of epoch 9, loss 3.136663844585419\n",
      "now time: 3:21. Step 200 of piece 0 of epoch 9, loss 2.004424078464508\n",
      "now time: 3:23. Step 300 of piece 0 of epoch 9, loss 2.0003432142734527\n",
      "now time: 3:26. Step 400 of piece 0 of epoch 9, loss 2.0081939208507538\n",
      "now time: 3:28. Step 500 of piece 0 of epoch 9, loss 1.9936890637874602\n",
      "now time: 3:30. Step 600 of piece 0 of epoch 9, loss 1.9920781135559082\n",
      "epoch 10\n",
      "time: 2020-04-16 03:32:05.659645\n",
      "now time: 3:34. Step 100 of piece 0 of epoch 10, loss 2.9409005546569826\n",
      "now time: 3:36. Step 200 of piece 0 of epoch 10, loss 1.873287514448166\n",
      "now time: 3:39. Step 300 of piece 0 of epoch 10, loss 1.8740946745872498\n",
      "now time: 3:41. Step 400 of piece 0 of epoch 10, loss 1.8776152431964874\n",
      "now time: 3:43. Step 500 of piece 0 of epoch 10, loss 1.8794782698154449\n",
      "now time: 3:46. Step 600 of piece 0 of epoch 10, loss 1.8748361718654634\n",
      "epoch 11\n",
      "time: 2020-04-16 03:47:19.714032\n",
      "now time: 3:49. Step 100 of piece 0 of epoch 11, loss 2.7505292212963104\n",
      "now time: 3:51. Step 200 of piece 0 of epoch 11, loss 1.7488766956329345\n",
      "now time: 3:54. Step 300 of piece 0 of epoch 11, loss 1.7564728021621705\n",
      "now time: 3:56. Step 400 of piece 0 of epoch 11, loss 1.7629074132442475\n",
      "now time: 3:58. Step 500 of piece 0 of epoch 11, loss 1.7594583714008332\n",
      "now time: 4:1. Step 600 of piece 0 of epoch 11, loss 1.7469587874412538\n",
      "epoch 12\n",
      "time: 2020-04-16 04:02:33.384908\n",
      "now time: 4:4. Step 100 of piece 0 of epoch 12, loss 2.5669286179542543\n",
      "now time: 4:7. Step 200 of piece 0 of epoch 12, loss 1.6365967988967896\n",
      "now time: 4:9. Step 300 of piece 0 of epoch 12, loss 1.6398653757572175\n",
      "now time: 4:11. Step 400 of piece 0 of epoch 12, loss 1.6442046630382539\n",
      "now time: 4:14. Step 500 of piece 0 of epoch 12, loss 1.642245318889618\n",
      "now time: 4:16. Step 600 of piece 0 of epoch 12, loss 1.6417443752288818\n",
      "epoch 13\n",
      "time: 2020-04-16 04:17:44.574765\n",
      "now time: 4:20. Step 100 of piece 0 of epoch 13, loss 2.4030781209468843\n",
      "now time: 4:22. Step 200 of piece 0 of epoch 13, loss 1.5256192553043366\n",
      "now time: 4:24. Step 300 of piece 0 of epoch 13, loss 1.5365435802936553\n",
      "now time: 4:27. Step 400 of piece 0 of epoch 13, loss 1.5389688789844513\n",
      "now time: 4:29. Step 500 of piece 0 of epoch 13, loss 1.5388435673713685\n",
      "now time: 4:31. Step 600 of piece 0 of epoch 13, loss 1.537399308681488\n",
      "epoch 14\n",
      "time: 2020-04-16 04:32:55.731805\n",
      "now time: 4:35. Step 100 of piece 0 of epoch 14, loss 2.245744732618332\n",
      "now time: 4:37. Step 200 of piece 0 of epoch 14, loss 1.4283682191371918\n",
      "now time: 4:39. Step 300 of piece 0 of epoch 14, loss 1.439707955121994\n",
      "now time: 4:42. Step 400 of piece 0 of epoch 14, loss 1.4385538804531097\n",
      "now time: 4:44. Step 500 of piece 0 of epoch 14, loss 1.4388358771800995\n",
      "now time: 4:46. Step 600 of piece 0 of epoch 14, loss 1.4463050270080566\n",
      "epoch 15\n",
      "time: 2020-04-16 04:48:07.590364\n",
      "now time: 4:50. Step 100 of piece 0 of epoch 15, loss 2.1014110934734345\n",
      "now time: 4:52. Step 200 of piece 0 of epoch 15, loss 1.3430095541477203\n",
      "now time: 4:55. Step 300 of piece 0 of epoch 15, loss 1.3440466809272766\n",
      "now time: 4:57. Step 400 of piece 0 of epoch 15, loss 1.3469557309150695\n",
      "now time: 4:59. Step 500 of piece 0 of epoch 15, loss 1.3533795082569122\n",
      "now time: 5:2. Step 600 of piece 0 of epoch 15, loss 1.350544846057892\n",
      "epoch 16\n",
      "time: 2020-04-16 05:03:21.359050\n",
      "now time: 5:5. Step 100 of piece 0 of epoch 16, loss 1.9660143125057221\n",
      "now time: 5:8. Step 200 of piece 0 of epoch 16, loss 1.2541267347335816\n",
      "now time: 5:10. Step 300 of piece 0 of epoch 16, loss 1.259226269721985\n",
      "now time: 5:12. Step 400 of piece 0 of epoch 16, loss 1.2658753824234008\n",
      "now time: 5:14. Step 500 of piece 0 of epoch 16, loss 1.2690154457092284\n",
      "now time: 5:17. Step 600 of piece 0 of epoch 16, loss 1.2719350898265838\n",
      "epoch 17\n",
      "time: 2020-04-16 05:18:33.537657\n",
      "now time: 5:20. Step 100 of piece 0 of epoch 17, loss 1.8483317708969116\n",
      "now time: 5:23. Step 200 of piece 0 of epoch 17, loss 1.1701875877380372\n",
      "now time: 5:25. Step 300 of piece 0 of epoch 17, loss 1.1864917719364165\n",
      "now time: 5:27. Step 400 of piece 0 of epoch 17, loss 1.1902322900295257\n",
      "now time: 5:30. Step 500 of piece 0 of epoch 17, loss 1.191501111984253\n",
      "now time: 5:32. Step 600 of piece 0 of epoch 17, loss 1.1947383069992066\n",
      "epoch 18\n",
      "time: 2020-04-16 05:33:44.124617\n",
      "now time: 5:36. Step 100 of piece 0 of epoch 18, loss 1.7342723166942597\n",
      "now time: 5:38. Step 200 of piece 0 of epoch 18, loss 1.1028614771366119\n",
      "now time: 5:40. Step 300 of piece 0 of epoch 18, loss 1.109117056131363\n",
      "now time: 5:43. Step 400 of piece 0 of epoch 18, loss 1.118437031507492\n",
      "now time: 5:45. Step 500 of piece 0 of epoch 18, loss 1.1209260213375092\n",
      "now time: 5:47. Step 600 of piece 0 of epoch 18, loss 1.124591029882431\n",
      "epoch 19\n",
      "time: 2020-04-16 05:48:56.031032\n",
      "now time: 5:51. Step 100 of piece 0 of epoch 19, loss 1.6284554076194764\n",
      "now time: 5:53. Step 200 of piece 0 of epoch 19, loss 1.0364246493577958\n",
      "now time: 5:55. Step 300 of piece 0 of epoch 19, loss 1.0447640657424926\n",
      "now time: 5:58. Step 400 of piece 0 of epoch 19, loss 1.0529798078536987\n",
      "now time: 6:0. Step 500 of piece 0 of epoch 19, loss 1.0552983176708222\n",
      "now time: 6:2. Step 600 of piece 0 of epoch 19, loss 1.0555978977680207\n",
      "epoch 20\n",
      "time: 2020-04-16 06:04:08.537717\n",
      "now time: 6:6. Step 100 of piece 0 of epoch 20, loss 1.5358845353126527\n",
      "now time: 6:8. Step 200 of piece 0 of epoch 20, loss 0.9747134763002395\n",
      "now time: 6:11. Step 300 of piece 0 of epoch 20, loss 0.9841806548833847\n",
      "now time: 6:13. Step 400 of piece 0 of epoch 20, loss 0.9879507029056549\n",
      "now time: 6:15. Step 500 of piece 0 of epoch 20, loss 0.9952266401052475\n",
      "now time: 6:18. Step 600 of piece 0 of epoch 20, loss 0.9997190886735916\n",
      "epoch 21\n",
      "time: 2020-04-16 06:19:19.802103\n",
      "now time: 6:21. Step 100 of piece 0 of epoch 21, loss 1.4491075098514556\n",
      "now time: 6:23. Step 200 of piece 0 of epoch 21, loss 0.9256779366731643\n",
      "now time: 6:26. Step 300 of piece 0 of epoch 21, loss 0.9296008312702179\n",
      "now time: 6:28. Step 400 of piece 0 of epoch 21, loss 0.9329792124032974\n",
      "now time: 6:30. Step 500 of piece 0 of epoch 21, loss 0.9387668401002884\n",
      "now time: 6:33. Step 600 of piece 0 of epoch 21, loss 0.9413994669914245\n",
      "epoch 22\n",
      "time: 2020-04-16 06:34:32.006479\n",
      "now time: 6:36. Step 100 of piece 0 of epoch 22, loss 1.369708793759346\n",
      "now time: 6:39. Step 200 of piece 0 of epoch 22, loss 0.8698766320943833\n",
      "now time: 6:41. Step 300 of piece 0 of epoch 22, loss 0.879535500407219\n",
      "now time: 6:43. Step 400 of piece 0 of epoch 22, loss 0.882276793718338\n",
      "now time: 6:46. Step 500 of piece 0 of epoch 22, loss 0.8877784383296966\n",
      "now time: 6:48. Step 600 of piece 0 of epoch 22, loss 0.8892823547124863\n",
      "epoch 23\n",
      "time: 2020-04-16 06:49:43.700830\n",
      "now time: 6:52. Step 100 of piece 0 of epoch 23, loss 1.3021733957529067\n",
      "now time: 6:54. Step 200 of piece 0 of epoch 23, loss 0.8236924302577973\n",
      "now time: 6:56. Step 300 of piece 0 of epoch 23, loss 0.835443131327629\n",
      "now time: 6:59. Step 400 of piece 0 of epoch 23, loss 0.8385501962900161\n",
      "now time: 7:1. Step 500 of piece 0 of epoch 23, loss 0.8440354722738266\n",
      "now time: 7:3. Step 600 of piece 0 of epoch 23, loss 0.8432110524177552\n",
      "epoch 24\n",
      "time: 2020-04-16 07:04:55.318724\n",
      "now time: 7:7. Step 100 of piece 0 of epoch 24, loss 1.23594005048275\n",
      "now time: 7:9. Step 200 of piece 0 of epoch 24, loss 0.784839220046997\n",
      "now time: 7:11. Step 300 of piece 0 of epoch 24, loss 0.795030711889267\n",
      "now time: 7:14. Step 400 of piece 0 of epoch 24, loss 0.7949240291118622\n",
      "now time: 7:16. Step 500 of piece 0 of epoch 24, loss 0.7992287290096283\n",
      "now time: 7:18. Step 600 of piece 0 of epoch 24, loss 0.8026183515787124\n",
      "epoch 25\n",
      "time: 2020-04-16 07:20:06.546957\n",
      "now time: 7:22. Step 100 of piece 0 of epoch 25, loss 1.1748134887218475\n",
      "now time: 7:24. Step 200 of piece 0 of epoch 25, loss 0.7487787473201751\n",
      "now time: 7:27. Step 300 of piece 0 of epoch 25, loss 0.7541225963830948\n",
      "now time: 7:29. Step 400 of piece 0 of epoch 25, loss 0.7591692370176315\n",
      "now time: 7:31. Step 500 of piece 0 of epoch 25, loss 0.7653062713146209\n",
      "now time: 7:34. Step 600 of piece 0 of epoch 25, loss 0.7620276564359665\n",
      "epoch 26\n",
      "time: 2020-04-16 07:35:15.116928\n",
      "now time: 7:37. Step 100 of piece 0 of epoch 26, loss 1.1271157205104827\n",
      "now time: 7:39. Step 200 of piece 0 of epoch 26, loss 0.7196405810117722\n",
      "now time: 7:42. Step 300 of piece 0 of epoch 26, loss 0.7242998188734054\n",
      "now time: 7:44. Step 400 of piece 0 of epoch 26, loss 0.725955114364624\n",
      "now time: 7:46. Step 500 of piece 0 of epoch 26, loss 0.725811847448349\n",
      "now time: 7:49. Step 600 of piece 0 of epoch 26, loss 0.7297996699810028\n",
      "epoch 27\n",
      "time: 2020-04-16 07:50:25.795469\n",
      "now time: 7:52. Step 100 of piece 0 of epoch 27, loss 1.07976269364357\n",
      "now time: 7:55. Step 200 of piece 0 of epoch 27, loss 0.6927031743526458\n",
      "now time: 7:57. Step 300 of piece 0 of epoch 27, loss 0.6950196087360382\n",
      "now time: 7:59. Step 400 of piece 0 of epoch 27, loss 0.6976888173818588\n",
      "now time: 8:2. Step 500 of piece 0 of epoch 27, loss 0.6997041636705399\n",
      "now time: 8:4. Step 600 of piece 0 of epoch 27, loss 0.6983793312311173\n",
      "epoch 28\n",
      "time: 2020-04-16 08:05:36.768842\n",
      "now time: 8:7. Step 100 of piece 0 of epoch 28, loss 1.041203372478485\n",
      "now time: 8:10. Step 200 of piece 0 of epoch 28, loss 0.6684932935237885\n",
      "now time: 8:12. Step 300 of piece 0 of epoch 28, loss 0.6704179030656815\n",
      "now time: 8:14. Step 400 of piece 0 of epoch 28, loss 0.6714022094011307\n",
      "now time: 8:17. Step 500 of piece 0 of epoch 28, loss 0.6705535060167312\n",
      "now time: 8:19. Step 600 of piece 0 of epoch 28, loss 0.6737305068969727\n",
      "epoch 29\n",
      "time: 2020-04-16 08:20:47.409262\n",
      "now time: 8:23. Step 100 of piece 0 of epoch 29, loss 1.0074528831243514\n",
      "now time: 8:25. Step 200 of piece 0 of epoch 29, loss 0.648998013138771\n",
      "now time: 8:27. Step 300 of piece 0 of epoch 29, loss 0.6515571510791779\n",
      "now time: 8:30. Step 400 of piece 0 of epoch 29, loss 0.6512559533119202\n",
      "now time: 8:32. Step 500 of piece 0 of epoch 29, loss 0.652387506365776\n",
      "now time: 8:34. Step 600 of piece 0 of epoch 29, loss 0.6522213840484619\n",
      "epoch 30\n",
      "time: 2020-04-16 08:35:58.999761\n",
      "now time: 8:38. Step 100 of piece 0 of epoch 30, loss 0.986364706158638\n",
      "now time: 8:40. Step 200 of piece 0 of epoch 30, loss 0.6341836673021316\n",
      "now time: 8:42. Step 300 of piece 0 of epoch 30, loss 0.6344272303581238\n",
      "now time: 8:45. Step 400 of piece 0 of epoch 30, loss 0.635601818561554\n",
      "now time: 8:47. Step 500 of piece 0 of epoch 30, loss 0.6358217197656632\n",
      "now time: 8:49. Step 600 of piece 0 of epoch 30, loss 0.6335765486955642\n",
      "training finished\n",
      "I0416 08:51:11.429557 140639139563328 configuration_utils.py:71] Configuration saved in tasks/doupo/model/final_model/config.json\n",
      "I0416 08:51:12.115916 140639139563328 modeling_utils.py:205] Model weights saved in tasks/doupo/model/final_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; bash train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型保存于`tasks/doupo/model/final_model`中，该文件夹下有两个文件，`config.json`，`pytorch_model.bin`。在`config.json`中包含了模型的基本参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 344M\n",
      "-rw-rw-r--  1 weijing weijing 344M Apr 16 08:51 pytorch_model.bin\n",
      "-rw-rw-r--  1 weijing weijing  596 Apr 16 08:51 config.json\n",
      "drwxrwxr-x  2 weijing weijing 4.0K Mar 31 06:32 .\n",
      "drwxrwxr-x 33 weijing weijing 4.0K Mar 31 06:32 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -laht tasks/doupo/model/final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch_model.bin`可以被直接加载，并能够输出模型结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 10:41:52.995795 140436257081152 configuration_utils.py:148] loading configuration file tasks/doupo/model/final_model/config.json\n",
      "I0416 10:41:52.998218 140436257081152 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "I0416 10:41:52.999756 140436257081152 modeling_utils.py:334] loading weights file tasks/doupo/model/final_model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21163, 768)\n",
      "    (wpe): Embedding(512, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21163, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained(\"tasks/doupo/model/final_model\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要查看模型中的参数个数，可以使用如下命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in the model is 87526656\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"The number of parameters in the model is %s\" % pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在训练好的模型上做Inference，生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate.py`脚本使用top-k sampling生成文本。`tasks/doupo/generate.sh`定义了top-k sampling的参数，如下所示，topk=50，nsamples=10，temperature=0.8，length=18，prefix=[SEP][CLS]萧炎。topk越小，多样性越低。temperature $T$也定义了多样性：取到词表中第i个词的概率由logits向量$z_{1:V}$和温度T决定, $q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$。具体的，T越大，向量$z_{1:V}$中各分量的绝对值就越趋向于0，造成多样性提高而采样质量下降；T越小，则各分量就越远离0，多样性下降而质量提升。一般的，top-k sampling中使用的T为0.8。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tjob_dir=\"tasks/doupo\"\n",
      "     2\t\n",
      "     3\tcd ../..\n",
      "     4\t\n",
      "     5\tif [ ! -e $job_dir/outputs ]; then\n",
      "     6\t    mkdir $job_dir/outputs\n",
      "     7\tfi\n",
      "     8\t\n",
      "     9\tpython generate.py \\\n",
      "    10\t    --device 0 \\\n",
      "    11\t    --model_path $job_dir/model/final_model/ \\\n",
      "    12\t    --model_config $job_dir/model/final_model/model_config.json \\\n",
      "    13\t    --tokenizer_path $job_dir/config/vocab.txt \\\n",
      "    14\t    --temperature 0.8 \\\n",
      "    15\t    --prefix [SEP][CLS]萧炎 \\\n",
      "    16\t    --length 100 \\\n",
      "    17\t    --topk 50 \\\n",
      "    18\t    --nsamples 10 \\\n",
      "    19\t    --save_samples \\\n",
      "    20\t    --save_samples_path $job_dir/outputs/\n"
     ]
    }
   ],
   "source": [
    "!cat -n tasks/doupo/generate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0416 09:33:09.533224 139695085782848 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "args:\n",
      "Namespace(batch_size=1, device='0', fast_pattern=False, length=100, model_config='tasks/doupo/model/final_model/model_config.json', model_path='tasks/doupo/model/final_model/', no_wordpiece=False, nsamples=10, prefix='[SEP][CLS]萧炎', repetition_penalty=1.0, save_samples=True, save_samples_path='tasks/doupo/outputs/', segment=False, temperature=0.8, tokenizer_path='tasks/doupo/config/vocab.txt', topk=50, topp=0)\n",
      "I0416 09:33:09.818720 139695085782848 configuration_utils.py:148] loading configuration file tasks/doupo/model/final_model/config.json\n",
      "I0416 09:33:09.819159 139695085782848 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "I0416 09:33:09.819901 139695085782848 modeling_utils.py:334] loading weights file tasks/doupo/model/final_model/pytorch_model.bin\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 142.36it/s]\n",
      "======================================== SAMPLE 1 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎目光平淡的望着那些闪掠而来的黑影，从纳戒中取出一块玉牌，玉牌之上，隐隐间渗透着一丝诡异紫色火焰。[SEP][CLS]那些细小的火焰缓缓飘荡在伤疤之上，整个房间之中，都是泛着一点点的光泽。[SEP][CLS]萧炎目光眨也不眨的盯着玉牌\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 144.02it/s]\n",
      "======================================== SAMPLE 2 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎微微点头，他并没有与魂殿有太大的恩怨，既然如此，也只能将这两次的麻烦解决。[SEP][CLS]“既然如此，那便现身，若是再留意的话，或许便是可以试试能否将你二人请到与菩提化体涎交予我。”[SEP][CLS]见到萧炎并未在意，丹塔老祖\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.70it/s]\n",
      "======================================== SAMPLE 3 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎手掌刚刚握下“天妖凰族的王八蛋”[SEP][CLS]心头松了一口气，眼中也是掠过一抹凝重，果然是名不虚传冉雨的斗技，而且还是真正的王族血脉，这等存在，方才是真正的血脉，在萧炎手中，也是真正的能够竞得上天妖凰族。[SEP][CLS]“\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.62it/s]\n",
      "======================================== SAMPLE 4 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎面色凝重，这种时候，他也是首次选择了手脚，未曾料到，这一次，是他的竞争对手，以前的速度虽略微有些狼狈，但也是完全不是他所希望的，当下只能一咬牙，速度急忙加快。[SEP][CLS]在萧炎加入掉曹颖与丹轩之前，曹颖，宋清\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.68it/s]\n",
      "======================================== SAMPLE 5 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的身形，在无数道震惊目光注视中，直接是诡异消失[SEP][CLS]原本高达几十米的北方天际之上，一闪间，便是消失在了天际之边。[SEP][CLS]“嘭！”[SEP][CLS]翎泉脚掌刚刚落地，一道低沉闷响突然自城外传来，旋即一道身影从城市之外暴掠而\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.10it/s]\n",
      "======================================== SAMPLE 6 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的目光，忽然转向一旁的石台，那里，一位身穿白衣的青年，正脸带微笑的缓缓走来，在他的面前，摆放着一个小袋，笑眯眯的望着他。[SEP][CLS]“这位老先生，如果您所说的是他的体内火毒，这些小女孩的体内正统，而且还全部都\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 139.50it/s]\n",
      "======================================== SAMPLE 7 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎笑了笑，也不在这个话题上继续纠缠，拱手道：“多谢姚坊主帮忙，今天的事，交给我便好。”[SEP][CLS]“姚坊主，我来此处，是你自己介绍的地方，多加我与大哥让得你再次共享这换丹药的资格。”见到萧炎摇头，那姚坊主却是摆\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 134.48it/s]\n",
      "======================================== SAMPLE 8 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎手掌轻轻碰撞，这股巨大的暗劲风涟漪，犹如涟漪一般，从那乱石堆中扩散而出，一时间，这片混乱战场，便是陷入了混乱的战场中。[SEP][CLS]广场边缘处，薰儿纤手一开飘落额前的青丝，淡淡的声音，在全场回荡着：“没想到这妮\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 134.20it/s]\n",
      "======================================== SAMPLE 9 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的目光，并未因为那黑甲身影的半点而有所停留，他的目光，死死的锁定着那不断蠕动的身体，但其他的那种熟悉，却是令得他的灵魂都是有种被绞碎的感觉，他明白，这是灵魂的主人！[SEP][CLS]“是灵魂力量体？”[SEP][CLS]萧炎的灵魂\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 133.47it/s]\n",
      "======================================== SAMPLE 10 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎笑了笑，也不说话，直接将话题转移到了最为激烈的大厅，笑吟吟的宣布着打滚的地方，今天的事，照旧围确是萧家的后辈，日后他们再次为萧家做了嫁衣，照料她回复了家族在加玛帝国的地位，日后若是还有机会，也尽数去抓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo;bash generate.sh;cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述文本生成结果保存于`tasks/doupo/generate.sh`中定义的`$save_samples_path`文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调GPT2模型进行数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节描述如何通过加载预训练模型，然后在较小的训练集上微调之后获得一个新的语言模型，并用于数据增强，为较少的训练样本提供模型生成的“数据增强”样本，其用途包括但不限定于为多轮对话中的意图识别训练样本进行数据增强，仿写具有某种语言风格的短小的文本。我们以对[海子的诗歌](https://github.com/sheepzh/poetry/tree/master/data/origin/%E6%B5%B7%E5%AD%90_haizi)进行数据增强为例进行说明这部分的使用方法：加载[散文预训练模型](https://www.dropbox.com/s/yqxuu6fszqto4od/pytorch_model.bin?dl=0)，然后使用海子的诗歌进行微调，最后使用海子的语言风格进行仿写。意图识别训练样本的数据增强也可以同理进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分的文件如下所示，`download.py`用于下载训练语料，`format_raw_txt.py`用于一定的数据处理，将处于不同文件中的语料合并到一个文件中，`finetune.sh`用于进行微调，作为对比`train_from_scratch.sh`用于在小样本训练集上从头训练一个语言模型。`generate_from_finetuned.sh`用于数据增强，`generate_from_scratch.sh`使用从头训练的语言模型进行文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtasks/dataaugmentation\u001b[00m\n",
      "├── download.py\n",
      "├── finetune.sh\n",
      "├── format_raw_txt.py\n",
      "├── generate_from_finetuned.sh\n",
      "├── generate_from_scratch.sh\n",
      "├── \u001b[01;34mrawdata\u001b[00m\n",
      "│   └── poem_list.txt\n",
      "└── train_from_scratch.sh\n",
      "\n",
      "1 directory, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree tasks/dataaugmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`download.py`读取`rawdata/poem_list.txt`，并下载海子的诗歌到`rawdata`文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'wget*': No such file or directory\n",
      "\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log’.\n",
      "\n",
      "Redirecting output to ‘wget-log.1’.\n",
      "\n",
      "Redirecting output to ‘wget-log.2’.\n",
      "\n",
      "Redirecting output to ‘wget-log.3’.\n",
      "\n",
      "Redirecting output to ‘wget-log.4’.\n",
      "\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.5’.\n",
      "\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.6’.\n",
      "\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.8’.\n",
      "\n",
      "Redirecting output to ‘wget-log.9’.\n",
      "\n",
      "Redirecting output to ‘wget-log.10’.\n",
      "\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.12’.\n",
      "\n",
      "Redirecting output to ‘wget-log.13’.\n",
      "\n",
      "Redirecting output to ‘wget-log.14’.\n",
      "\n",
      "Redirecting output to ‘wget-log.15’.\n",
      "\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.16’.\n",
      "\n",
      "Redirecting output to ‘wget-log.17’.\n",
      "\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.18’.\n",
      "\n",
      "Redirecting output to ‘wget-log.19’.\n",
      "\n",
      "Redirecting output to ‘wget-log.20’.\n",
      "\n",
      "Redirecting output to ‘wget-log.7’.\n",
      "\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.11’.\n",
      "\n",
      "SIGHUP received.\n",
      "Redirecting output to ‘wget-log.21’.\n",
      "\n",
      "Redirecting output to ‘wget-log.22’.\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; python download.py rawdata; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls -laht tasks/dataaugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'wget-log*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; rm wget-log*; cd ../..; #去除多余的wget-log*日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载之后，共有143首诗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 weijing weijing  400 Apr 16 14:24 rawdata/莲界慈航.pt\n",
      "-rw-rw-r-- 1 weijing weijing  829 Apr 16 14:24 rawdata/盲目——给维特根施坦.pt\n",
      "-rw-rw-r-- 1 weijing weijing  824 Apr 16 14:24 rawdata/黑风.pt\n",
      "-rw-rw-r-- 1 weijing weijing  364 Apr 16 14:24 rawdata/自杀者之歌.pt\n",
      "-rw-rw-r-- 1 weijing weijing  441 Apr 16 14:24 rawdata/敦煌.pt\n",
      "-rw-rw-r-- 1 weijing weijing  429 Apr 16 14:24 rawdata/黄金草原.pt\n",
      "-rw-rw-r-- 1 weijing weijing  517 Apr 16 14:24 rawdata/雨鞋.pt\n",
      "-rw-rw-r-- 1 weijing weijing  337 Apr 16 14:24 rawdata/黎明：一首小诗.pt\n",
      "-rw-rw-r-- 1 weijing weijing  261 Apr 16 14:24 rawdata/魂曲.pt\n",
      "-rw-rw-r-- 1 weijing weijing  773 Apr 16 14:24 rawdata/马、火、灰——鼎.pt\n",
      "ls: write error: Broken pipe\n",
      "...\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; ls -laht rawdata/*.pt | head -n 10; echo \"...\"; ls -laht rawdata/*.pt | wc -l; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始文件中，诗歌自然分行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:莲界慈航\n",
      "date:198505\n",
      "\n",
      "七叶树下\n",
      "九根香\n",
      "照见菩萨的\n",
      "第一次失恋\n",
      "\n",
      "你盘坐莲花\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; head -n 10 rawdata/莲界慈航.pt; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更好的训练，我们使用`format_raw_txt.py`进行处理，让一首诗独占一行。我们使用[MASK]来代替回车符，使用[unused1]来代替空格符\" \"，其中[unused1]出现在bert chinese的字表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t'''\n",
      "     2\tturn the following file into a line in train.txt\n",
      "     3\ttitle:月\n",
      "     4\tdate:\n",
      "     5\t\n",
      "     6\t炊烟上下\n",
      "     7\t月亮是掘井的白猿\n",
      "     8\t月亮是惨笑的河流上的白猿\n",
      "     9\t\n",
      "    10\t多少回天上的伤口淌血\n",
      "    11\t白猿流过钟楼\n",
      "    12\t流过南方老人的头顶\n",
      "    13\t\n",
      "    14\t掘井的白猿\n",
      "    15\t村庄喂养的白猿\n",
      "    16\t月亮是惨笑的白猿\n",
      "    17\t月亮自己心碎\n",
      "    18\t月亮早已心碎\n",
      "    19\t\n",
      "    20\t==>\n",
      "    21\t月[MASK][MASK]炊烟上下[MASK]月亮是掘井的白猿[MASK]月亮是惨笑的河流上的白猿[MASK][MASK]多少回天上的伤口淌血...\n",
      "    22\tRule 1: replace \\n with [MASK]\n",
      "    23\tRule 2: replace the whitespace \" \" with [unused1] \n",
      "    24\t'''\n",
      "    25\t\n",
      "    26\timport os\n",
      "    27\timport sys\n",
      "    28\timport pdb\n",
      "    29\t\n",
      "    30\tdef format(foldername):\n",
      "    31\t    files = [f for f in os.listdir(foldername) if \".pt\" in f]\n",
      "    32\t    # pdb.set_trace()\n",
      "    33\t    with open(foldername+\"/\"+\"train.txt\", \"w\") as fWriter:\n",
      "    34\t        for filename in files:\n",
      "    35\t            result = \"\"\n",
      "    36\t            with open(foldername+\"/\"+filename, \"r\") as fIn:\n",
      "    37\t                for line in fIn:\n",
      "    38\t                    if(\"title:\" in line):\n",
      "    39\t                        result += line.strip(\"title:\").replace(\"\\n\", \"[MASK]\")\n",
      "    40\t                    elif(\"date:\" in line):\n",
      "    41\t                        result += \"[MASK]\"\n",
      "    42\t                    else:\n",
      "    43\t                        result += line.replace(\"\\n\", \"[MASK]\").replace(\" \", \"[unused1]\")\n",
      "    44\t            fWriter.write(\"%s\\n\" % result)\n",
      "    45\t\n",
      "    46\tdef test():\n",
      "    47\t    format(\"rawdata\")\n",
      "    48\t\n",
      "    49\t\n",
      "    50\tif __name__==\"__main__\":\n",
      "    51\t    if(len(sys.argv)!=2):\n",
      "    52\t        print(\"usage: python format_raw_txt.py target_folder\")\n",
      "    53\t        sys.exit(0)\n",
      "    54\t    else:\n",
      "    55\t        target_folder = sys.argv[1]\n",
      "    56\t        format(target_folder)\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; cat -n format_raw_txt.py; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了能在`train.txt`的不同的行（即不同的文本）之间进行区分，我们使用[CLS]来表示一行的开头，[SEP]表示一行的结束，如果不足n_ctx，那么就用[PAD]来补齐。例如，line1字符数超过n_ctx-2，line2和line3则未超过，那么：`line1\\nline2\\nline3` => '[CLS]line1(trimmed)[SEP][CLS]line2[SEP][PAD]...[PAD][CLS]line3[SEP][PAD]...[PAD]'。这一处理过程体现于`train_on_small_file.py`的第102行到116行之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102     print('start preparing data')\n",
      "103     contents = []\n",
      "104     for line in lines:\n",
      "105         line = line.strip()\n",
      "106         if(len(line)>(n_ctx-2)):\n",
      "107             line = line[0:(n_ctx-2)] # trim out very long sequences\n",
      "108         contents.append(full_tokenizer.convert_tokens_to_ids(full_tokenizer._tokenize(line)))\n",
      "109     tokens = []\n",
      "110     for content in contents:\n",
      "111         token = []\n",
      "112         token.append(full_tokenizer.convert_tokens_to_ids('[CLS]'))\n",
      "113         token.extend(content)\n",
      "114         token.append(full_tokenizer.convert_tokens_to_ids('[SEP]'))\n",
      "115         token.extend(full_tokenizer.convert_tokens_to_ids(['[PAD]'])*(n_ctx-len(token)) )\n",
      "116         tokens.append(token)\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=102 and $.<=116)' train_on_small_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练过程中，由于一个样本占据一个n_ctx长度的输入，因此样本和样本之间是完全独立的，random shuffle之后的训练质量也较好。如下代码所示，每一个`batch`取了`batch_size`个样本进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118     print('starting training')\n",
      "119     running_loss = 0\n",
      "120     for epoch in range(epochs):\n",
      "121         print('epoch {}'.format(epoch + 1))\n",
      "122         now = datetime.now()\n",
      "123         print('time: {}'.format(now))\n",
      "124         samples = tokens\n",
      "125         random.shuffle(samples)\n",
      "126         for step in range(len(samples) // batch_size): # drop last\n",
      "127 \n",
      "128             #  prepare data\n",
      "129             batch = samples[step * batch_size: (step + 1) * batch_size]\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=118 and $.<=129)' train_on_small_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`finetune.sh`脚本中，创建pretrained_model文件夹，并将[散文预训练模型](https://drive.google.com/drive/folders/1rJC4niJKMVwixUQkuL9k5teLRnEYTmUf)保存于该文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 if [ ! -e $job_dir/pretrained_model ]; then\n",
      "14     mkdir $job_dir/pretrained_model\n",
      "15     wget -c -O $job_dir/pretrained_model/pytorch_model.bin https://www.dropbox.com/s/yqxuu6fszqto4od/pytorch_model.bin?dl=0\n",
      "16     wget -c -O $job_dir/pretrained_model/config.json https://www.dropbox.com/s/7z599ixdzyghkth/config.json?dl=0 \n",
      "17     wget -c -O $job_dir/pretrained_model/vocab.txt https://www.dropbox.com/s/9obd0qadtst347l/vocab.txt?dl=0 \n",
      "18 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; perl -ne 'print \"$. $_\" if ($.>=13 and $.<=18)' finetune.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于需要数据增强的文本规模较小，因此不需要分割文件和提前保存好tokenization的结果。我们可以直接确定好训练参数，然后开始进行finetuning。如下所示，epochs=30，使用双卡训练，使用`--pretrained_model`来指定需要加载的预训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 \n",
      "28 pretrained_model=$job_dir/pretrained_model\n",
      "29 raw_data_path=$job_dir/rawdata/train.txt\n",
      "30 tokenizer_path=$job_dir/pretrained_model/vocab.txt\n",
      "31 model_config=$job_dir/pretrained_model/config.json\n",
      "32 epochs=30\n",
      "33 batch_size=8\n",
      "34 log_step=8\n",
      "35 output_dir=$job_dir/model_finetuned/\n",
      "36 num_pieces=1\n",
      "37 \n",
      "38 python train_on_small_file.py \\\n",
      "39     --pretrained_model $pretrained_model \\\n",
      "40     --raw_data_path $raw_data_path \\\n",
      "41     --tokenizer_path $tokenizer_path \\\n",
      "42     --model_config $model_config \\\n",
      "43     --epochs $epochs \\\n",
      "44     --batch_size $batch_size \\\n",
      "45     --log_step $log_step \\\n",
      "46     --output_dir $output_dir \\\n",
      "47     --num_pieces $num_pieces \\\n",
      "48     --device 0,1 \\\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; perl -ne 'print \"$. $_\" if ($.>=27 and $.<=48)' finetune.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weijing/git/GPT2-Chinese/tasks/dataaugmentation\n",
      "--2020-04-16 15:46:03--  https://www.dropbox.com/s/yqxuu6fszqto4od/pytorch_model.bin?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/yqxuu6fszqto4od/pytorch_model.bin [following]\n",
      "--2020-04-16 15:46:03--  https://www.dropbox.com/s/raw/yqxuu6fszqto4od/pytorch_model.bin\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com/cd/0/inline/A19ErhvAYbh4zhE7XWPBqkV1ec1JktrpHNt9kSgNbO1JEzYgS-PFg0lpWRCzpU20oUZIo1oOao6G8MsaB8KbpaGgnYbyw7t3ZmJykQU4FY7DD15y_V4Ih_TqD5Rc6AvRLxo/file# [following]\n",
      "--2020-04-16 15:46:04--  https://uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com/cd/0/inline/A19ErhvAYbh4zhE7XWPBqkV1ec1JktrpHNt9kSgNbO1JEzYgS-PFg0lpWRCzpU20oUZIo1oOao6G8MsaB8KbpaGgnYbyw7t3ZmJykQU4FY7DD15y_V4Ih_TqD5Rc6AvRLxo/file\n",
      "Resolving uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com (uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com)... 162.125.3.6\n",
      "Connecting to uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com (uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/A1988NXdwvCHe-1Z3HSSxDZnbJAuCZXBSqfFbobRMWJ8t6KABc2yhZaB-oRnAEJmCMhO4P2JFxbKKKDI6wksOVzr8T6OIQ8oFgwP6mSsdRkbNAAiPCXEjkmXf1sbxeS6Cf54ZNNzhPTnvRT4e5X5Wac7ymDdsVqp5Bc1pC5j2aZnEwDpjaluyKPOYVkQ0udO6EfSjbWaWa5JrsTA4izMGb_O41X7Ms14OftpeX5uNKAROKTe0VKdUGH9AW-NpbBJ38-mmQWbH9UodR0GzyDRBrVpikvbJzDp_mVvW1gK86rHAqHtwxbU7K6u8GdrjKAG3ZIiy1kaLkvPCx1T9ESDfT0mKHO_qCvy2T4FpKBzWzQLbA/file [following]\n",
      "--2020-04-16 15:46:04--  https://uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com/cd/0/inline2/A1988NXdwvCHe-1Z3HSSxDZnbJAuCZXBSqfFbobRMWJ8t6KABc2yhZaB-oRnAEJmCMhO4P2JFxbKKKDI6wksOVzr8T6OIQ8oFgwP6mSsdRkbNAAiPCXEjkmXf1sbxeS6Cf54ZNNzhPTnvRT4e5X5Wac7ymDdsVqp5Bc1pC5j2aZnEwDpjaluyKPOYVkQ0udO6EfSjbWaWa5JrsTA4izMGb_O41X7Ms14OftpeX5uNKAROKTe0VKdUGH9AW-NpbBJ38-mmQWbH9UodR0GzyDRBrVpikvbJzDp_mVvW1gK86rHAqHtwxbU7K6u8GdrjKAG3ZIiy1kaLkvPCx1T9ESDfT0mKHO_qCvy2T4FpKBzWzQLbA/file\n",
      "Reusing existing connection to uc043e13a73172d0cce8685692d0.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 393543908 (375M) [application/octet-stream]\n",
      "Saving to: ‘tasks/dataaugmentation/pretrained_model/pytorch_model.bin’\n",
      "\n",
      "tasks/dataaugmentat 100%[===================>] 375.31M  40.8MB/s    in 9.9s    \n",
      "\n",
      "2020-04-16 15:46:15 (38.1 MB/s) - ‘tasks/dataaugmentation/pretrained_model/pytorch_model.bin’ saved [393543908/393543908]\n",
      "\n",
      "--2020-04-16 15:46:15--  https://www.dropbox.com/s/7z599ixdzyghkth/config.json?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/7z599ixdzyghkth/config.json [following]\n",
      "--2020-04-16 15:46:15--  https://www.dropbox.com/s/raw/7z599ixdzyghkth/config.json\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com/cd/0/inline/A18hw8mqDcYy5f7GHuhgXqTbINRvGeVyVepbiu4vNkkO9IaAbnoHUpCWMIx3bLjVFtJ1y3yFCN6aJkobdX1Z8rACOKmDLk_tdmIM7zWUPx8TeR5HWLsa6Oc-YtkFuwR7a9M/file# [following]\n",
      "--2020-04-16 15:46:15--  https://ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com/cd/0/inline/A18hw8mqDcYy5f7GHuhgXqTbINRvGeVyVepbiu4vNkkO9IaAbnoHUpCWMIx3bLjVFtJ1y3yFCN6aJkobdX1Z8rACOKmDLk_tdmIM7zWUPx8TeR5HWLsa6Oc-YtkFuwR7a9M/file\n",
      "Resolving ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com (ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com)... 162.125.3.6\n",
      "Connecting to ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com (ucc181ab3399933bfc4dcee94c40.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 550 [text/plain]\n",
      "Saving to: ‘tasks/dataaugmentation/pretrained_model/config.json’\n",
      "\n",
      "tasks/dataaugmentat 100%[===================>]     550  --.-KB/s    in 0s      \n",
      "\n",
      "2020-04-16 15:46:15 (54.0 MB/s) - ‘tasks/dataaugmentation/pretrained_model/config.json’ saved [550/550]\n",
      "\n",
      "--2020-04-16 15:46:15--  https://www.dropbox.com/s/9obd0qadtst347l/vocab.txt?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/9obd0qadtst347l/vocab.txt [following]\n",
      "--2020-04-16 15:46:16--  https://www.dropbox.com/s/raw/9obd0qadtst347l/vocab.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com/cd/0/inline/A1-KeVdDDgHWHDAi3oOm-89QGbFUpu91_vaJ3EYrEQ8mO5qPimr5KmZNVvGP9zyeN5RTn8k1TBY-599lSaWeAe1mlwVmBiRkgGgz3kDyPoe9I8aKiwSda4XkoNZPShpFByI/file# [following]\n",
      "--2020-04-16 15:46:16--  https://uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com/cd/0/inline/A1-KeVdDDgHWHDAi3oOm-89QGbFUpu91_vaJ3EYrEQ8mO5qPimr5KmZNVvGP9zyeN5RTn8k1TBY-599lSaWeAe1mlwVmBiRkgGgz3kDyPoe9I8aKiwSda4XkoNZPShpFByI/file\n",
      "Resolving uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com (uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com)... 162.125.3.6\n",
      "Connecting to uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com (uca650ebc9b2965495ab99f39fab.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 109516 (107K) [text/plain]\n",
      "Saving to: ‘tasks/dataaugmentation/pretrained_model/vocab.txt’\n",
      "\n",
      "tasks/dataaugmentat 100%[===================>] 106.95K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-04-16 15:46:17 (2.34 MB/s) - ‘tasks/dataaugmentation/pretrained_model/vocab.txt’ saved [109516/109516]\n",
      "\n",
      "I0416 15:46:18.576040 140309179840320 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "args:\n",
      "Namespace(batch_size=8, device='0,1', epochs=30, fp16=False, fp16_opt_level='O1', gradient_accumulation=1, ignore_intermediate_epoch_model=True, log_step=8, lr=0.00015, max_grad_norm=1.0, model_config='tasks/dataaugmentation/pretrained_model/config.json', num_pieces=1, output_dir='tasks/dataaugmentation/model_finetuned/', pretrained_model='tasks/dataaugmentation/pretrained_model', raw_data_path='tasks/dataaugmentation/rawdata/train.txt', segment=False, stride=768, tokenizer_path='tasks/dataaugmentation/pretrained_model/vocab.txt', warmup_steps=2000)\n",
      "config:\n",
      "{\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "using device: cuda\n",
      "I0416 15:46:18.883362 140309179840320 configuration_utils.py:148] loading configuration file tasks/dataaugmentation/pretrained_model/config.json\n",
      "I0416 15:46:18.883758 140309179840320 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "I0416 15:46:18.884530 140309179840320 modeling_utils.py:334] loading weights file tasks/dataaugmentation/pretrained_model/pytorch_model.bin\n",
      "calculating total steps\n",
      "total steps = 17\n",
      "Let's use 2 GPUs!\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:26: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "start preparing data\n",
      "starting training\n",
      "epoch 1\n",
      "time: 2020-04-16 15:46:24.084376\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "now time: 15:46. Step 8 of piece 0 of epoch 1, loss 14.76872706413269\n",
      "now time: 15:46. Step 16 of piece 0 of epoch 1, loss 14.180721044540405\n",
      "epoch 2\n",
      "time: 2020-04-16 15:46:41.277161\n",
      "now time: 15:46. Step 8 of piece 0 of epoch 2, loss 13.826103448867798\n",
      "now time: 15:46. Step 16 of piece 0 of epoch 2, loss 10.509986639022827\n",
      "epoch 3\n",
      "time: 2020-04-16 15:46:55.883379\n",
      "now time: 15:47. Step 8 of piece 0 of epoch 3, loss 9.374760329723358\n",
      "now time: 15:47. Step 16 of piece 0 of epoch 3, loss 6.113095164299011\n",
      "epoch 4\n",
      "time: 2020-04-16 15:47:10.513719\n",
      "now time: 15:47. Step 8 of piece 0 of epoch 4, loss 4.482836812734604\n",
      "now time: 15:47. Step 16 of piece 0 of epoch 4, loss 2.4589659571647644\n",
      "epoch 5\n",
      "time: 2020-04-16 15:47:25.227471\n",
      "now time: 15:47. Step 8 of piece 0 of epoch 5, loss 1.8635721057653427\n",
      "now time: 15:47. Step 16 of piece 0 of epoch 5, loss 1.1662150248885155\n",
      "epoch 6\n",
      "time: 2020-04-16 15:47:39.977764\n",
      "now time: 15:47. Step 8 of piece 0 of epoch 6, loss 1.193222738802433\n",
      "now time: 15:47. Step 16 of piece 0 of epoch 6, loss 0.8778059557080269\n",
      "epoch 7\n",
      "time: 2020-04-16 15:47:54.899470\n",
      "now time: 15:48. Step 8 of piece 0 of epoch 7, loss 1.123337760567665\n",
      "now time: 15:48. Step 16 of piece 0 of epoch 7, loss 0.771673321723938\n",
      "epoch 8\n",
      "time: 2020-04-16 15:48:09.802489\n",
      "now time: 15:48. Step 8 of piece 0 of epoch 8, loss 0.8658707551658154\n",
      "now time: 15:48. Step 16 of piece 0 of epoch 8, loss 0.8143178224563599\n",
      "epoch 9\n",
      "time: 2020-04-16 15:48:24.687853\n",
      "now time: 15:48. Step 8 of piece 0 of epoch 9, loss 0.84231036901474\n",
      "now time: 15:48. Step 16 of piece 0 of epoch 9, loss 0.7553895339369774\n",
      "epoch 10\n",
      "time: 2020-04-16 15:48:39.579433\n",
      "now time: 15:48. Step 8 of piece 0 of epoch 10, loss 0.8068016469478607\n",
      "now time: 15:48. Step 16 of piece 0 of epoch 10, loss 0.7175023481249809\n",
      "epoch 11\n",
      "time: 2020-04-16 15:48:54.518256\n",
      "now time: 15:49. Step 8 of piece 0 of epoch 11, loss 0.8304944112896919\n",
      "now time: 15:49. Step 16 of piece 0 of epoch 11, loss 0.6999380327761173\n",
      "epoch 12\n",
      "time: 2020-04-16 15:49:09.488469\n",
      "now time: 15:49. Step 8 of piece 0 of epoch 12, loss 0.7841717600822449\n",
      "now time: 15:49. Step 16 of piece 0 of epoch 12, loss 0.7316871732473373\n",
      "epoch 13\n",
      "time: 2020-04-16 15:49:24.468189\n",
      "now time: 15:49. Step 8 of piece 0 of epoch 13, loss 0.824965700507164\n",
      "now time: 15:49. Step 16 of piece 0 of epoch 13, loss 0.5941825434565544\n",
      "epoch 14\n",
      "time: 2020-04-16 15:49:39.398269\n",
      "now time: 15:49. Step 8 of piece 0 of epoch 14, loss 0.6487108767032623\n",
      "now time: 15:49. Step 16 of piece 0 of epoch 14, loss 0.7375681586563587\n",
      "epoch 15\n",
      "time: 2020-04-16 15:49:54.372953\n",
      "now time: 15:50. Step 8 of piece 0 of epoch 15, loss 0.7196302898228168\n",
      "now time: 15:50. Step 16 of piece 0 of epoch 15, loss 0.636940848082304\n",
      "epoch 16\n",
      "time: 2020-04-16 15:50:09.415317\n",
      "now time: 15:50. Step 8 of piece 0 of epoch 16, loss 0.7819686159491539\n",
      "now time: 15:50. Step 16 of piece 0 of epoch 16, loss 0.568371195346117\n",
      "epoch 17\n",
      "time: 2020-04-16 15:50:24.405588\n",
      "now time: 15:50. Step 8 of piece 0 of epoch 17, loss 0.6497973017394543\n",
      "now time: 15:50. Step 16 of piece 0 of epoch 17, loss 0.6325166113674641\n",
      "epoch 18\n",
      "time: 2020-04-16 15:50:39.729857\n",
      "now time: 15:50. Step 8 of piece 0 of epoch 18, loss 0.6766480281949043\n",
      "now time: 15:50. Step 16 of piece 0 of epoch 18, loss 0.5513135716319084\n",
      "epoch 19\n",
      "time: 2020-04-16 15:50:54.755115\n",
      "now time: 15:51. Step 8 of piece 0 of epoch 19, loss 0.5896020084619522\n",
      "now time: 15:51. Step 16 of piece 0 of epoch 19, loss 0.6137656606733799\n",
      "epoch 20\n",
      "time: 2020-04-16 15:51:09.717279\n",
      "now time: 15:51. Step 8 of piece 0 of epoch 20, loss 0.5851522758603096\n",
      "now time: 15:51. Step 16 of piece 0 of epoch 20, loss 0.562728613615036\n",
      "epoch 21\n",
      "time: 2020-04-16 15:51:24.665811\n",
      "now time: 15:51. Step 8 of piece 0 of epoch 21, loss 0.6030407845973969\n",
      "now time: 15:51. Step 16 of piece 0 of epoch 21, loss 0.4420272186398506\n",
      "epoch 22\n",
      "time: 2020-04-16 15:51:39.668481\n",
      "now time: 15:51. Step 8 of piece 0 of epoch 22, loss 0.5301626473665237\n",
      "now time: 15:51. Step 16 of piece 0 of epoch 22, loss 0.4707188494503498\n",
      "epoch 23\n",
      "time: 2020-04-16 15:51:54.741377\n",
      "now time: 15:52. Step 8 of piece 0 of epoch 23, loss 0.46980761736631393\n",
      "now time: 15:52. Step 16 of piece 0 of epoch 23, loss 0.45462706685066223\n",
      "epoch 24\n",
      "time: 2020-04-16 15:52:09.785949\n",
      "now time: 15:52. Step 8 of piece 0 of epoch 24, loss 0.4325726442039013\n",
      "now time: 15:52. Step 16 of piece 0 of epoch 24, loss 0.43158362433314323\n",
      "epoch 25\n",
      "time: 2020-04-16 15:52:24.800304\n",
      "now time: 15:52. Step 8 of piece 0 of epoch 25, loss 0.3912990614771843\n",
      "now time: 15:52. Step 16 of piece 0 of epoch 25, loss 0.4044934920966625\n",
      "epoch 26\n",
      "time: 2020-04-16 15:52:39.688603\n",
      "now time: 15:52. Step 8 of piece 0 of epoch 26, loss 0.37904636189341545\n",
      "now time: 15:52. Step 16 of piece 0 of epoch 26, loss 0.3112480044364929\n",
      "epoch 27\n",
      "time: 2020-04-16 15:52:54.676713\n",
      "now time: 15:53. Step 8 of piece 0 of epoch 27, loss 0.35180964693427086\n",
      "now time: 15:53. Step 16 of piece 0 of epoch 27, loss 0.30168329179286957\n",
      "epoch 28\n",
      "time: 2020-04-16 15:53:09.666120\n",
      "now time: 15:53. Step 8 of piece 0 of epoch 28, loss 0.34160003438591957\n",
      "now time: 15:53. Step 16 of piece 0 of epoch 28, loss 0.2553107254207134\n",
      "epoch 29\n",
      "time: 2020-04-16 15:53:24.630840\n",
      "now time: 15:53. Step 8 of piece 0 of epoch 29, loss 0.27494731917977333\n",
      "now time: 15:53. Step 16 of piece 0 of epoch 29, loss 0.2194879986345768\n",
      "epoch 30\n",
      "time: 2020-04-16 15:53:39.759252\n",
      "now time: 15:53. Step 8 of piece 0 of epoch 30, loss 0.24646927043795586\n",
      "now time: 15:53. Step 16 of piece 0 of epoch 30, loss 0.19037740677595139\n",
      "training finished\n",
      "I0416 15:53:54.794027 140309179840320 configuration_utils.py:71] Configuration saved in tasks/dataaugmentation/model_finetuned/final_model/config.json\n",
      "I0416 15:53:55.056300 140309179840320 modeling_utils.py:205] Model weights saved in tasks/dataaugmentation/model_finetuned/final_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/dataaugmentation; pwd; bash finetune.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weijing/git/GPT2-Chinese\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
