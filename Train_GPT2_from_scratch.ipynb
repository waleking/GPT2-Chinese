{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所需环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformers版本号为2.1.1，pytorch为1.2.0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 15:24:11.910086 140436257081152 file_utils.py:39] PyTorch version 1.2.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在requirments.txt中，列出了所需要的其他的包，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==2.1.1\n",
      "torch\n",
      "numpy\n",
      "tqdm\n",
      "sklearn\n",
      "keras\n",
      "tb-nightly\n",
      "future\n",
      "thulac\n"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录结构以及重要文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前文件夹中包含的文件如下。其中**doupo**文件夹下包含“斗破苍穹”的示例任务，用以简单说明如何构建字典、tokenization、以及在一个小文件上从头训练一个指定层数的GPT模型；**pretrain**文件夹下包含预训练任务，主要用以说明如何在260万篇新闻文档上预训练一个12层的GPT2；**dataaugmentation**文件夹下包含数据增强任务，主要用以说明如何利用预训练的GPT2模型在较小的文档集上进行微调，并用于数据增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├── cache\n",
      "├── config\n",
      "├── dataaugmentation\n",
      "├── eval.py\n",
      "├── generate.py\n",
      "├── generate_texts.py\n",
      "├── LICENSE\n",
      "├── pretrain\n",
      "├── README.md\n",
      "├── requirements.txt\n",
      "├── sample\n",
      "├── tasks\n",
      "├── tokenizations\n",
      "├── Train_GPT2_from_scratch.ipynb\n",
      "├── train.json\n",
      "├── train_on_small_file.py\n",
      "└── train_single.py\n",
      "\n",
      "7 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree -L 1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要重点加以说明的是，上述列表中的tokenizations文件夹，train_single.py, 和train_on_small_file.py。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizations`提供了各种tokenization的方法，具体到本代码库中，使用的是该文件夹中的`tokenization_chars.py`文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization的第一阶段是将纯文本文件依照字典文件vocab.txt进行划分为token，第二阶段是将token转化为字典文件中token对应的数字。举例来说，\"[CLS]《斗破苍穹》天蚕土豆[SEP][CLS] ...\"在第一阶段被分割为列表：['[CLS]', '《', '斗', '破', '苍', '穹', '》', '天', '蚕', '土', '豆', '[SEP]', '[CLS]', ...]，其中[CLS], [SEP]在vocab.txt对应一个单独的占位符；第二阶段在查找vocab.txt之后，将字符串列表转化为整型数列表：101 517 3159 4788 5721 4957 518 1921 6014 1759 6486 102 101。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下是tokenization第一阶段的代码，输入为text字符串，输出为字符串列表result，对于形如[.\\*]的特殊字符使用栈来处理：如果该特殊字符出现在vocab.txt中，则被提取为一个单独的字符串存入列表中，如161行所示；反之若没有出现在vocab.txt中，则逐字符加入到列表中，如163-165行所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140     def _tokenize(self, text):\n",
      "141         #pdb.set_trace()\n",
      "142         stack = []\n",
      "143 \n",
      "144         result = []\n",
      "145         i = 0\n",
      "146         len_txt = len(text)\n",
      "147         while(i<len_txt):\n",
      "148             char = text[i]\n",
      "149             if(len(stack)==0):\n",
      "150                 if(char != '['):\n",
      "151                     result.append(char)\n",
      "152                 else:\n",
      "153                     stack.append('[')\n",
      "154             else:\n",
      "155                 if(char == ']'):\n",
      "156                     stack.append(char) # don't forget to append it firstly\n",
      "157                     # process the content in the stack\n",
      "158                     seq = \"\".join(stack)\n",
      "159                     if(seq in self.vocab):\n",
      "160                         # the [.*] stuff appeared in the vocabulary, e.g. [UNK], [CLS], [SEP], ...\n",
      "161                         result.append(seq)\n",
      "162                     else:\n",
      "163                         # other [.*] stuff which are not valid element in the vocabulary\n",
      "164                         for e in stack:\n",
      "165                             result.append(e)\n",
      "166                     # clean the stack after processing \n",
      "167                     stack = []    \n",
      "168                 else:\n",
      "169                     stack.append(char)\n",
      "170             i += 1\n",
      "171 \n",
      "172         if(len(stack)>0): \n",
      "173             for e in stack:\n",
      "174                 result.append(e)\n",
      "175         # pdb.set_trace()\n",
      "176         return result\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=140 and $.<=176)' tokenizations/tokenization_chars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization的第二部分如下所示，对第一阶段获得的result列表中的token字符串进行查表操作，如果没有出现在vocab.txt中，那么就以[UNK]对应的id来代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178     def _convert_token_to_id(self, token):\n",
      "179         \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
      "180         #if(token not in self.vocab):\n",
      "181         #    print(token)\n",
      "182         return self.vocab.get(token, self.vocab.get(self.unk_token))\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=178 and $.<=182)' tokenizations/tokenization_chars.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，本代码库中的tokenization方法主要为中文设计，如果训练数据中混杂有英文字符，那么就将英文单词按照char level进行划分，例如\"word\"会被\"w\",\"o\",\"r\",\"d\"四个字符来代替。不同于BPE的方法，我们认为这样处理是最节省计算资源的，比起BPE能够更从容应对几十GB的中文训练语料。从具体的实际效果来看，在斗破苍穹的语料上进行tokenization，普通方法需要耗时77.9秒，使用了我们的方法之后，耗时12.1秒，用时为原来的15%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两种训练方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_single.py`：当输入的训练数据为一篇完整的长文档（例如小说）或是一个单一的大型文档，此时使用`train_single.py`。有两方面的原因。（1）train_single.py在训练过程中不对training samples进行random shuffle，保持training samples之间的顺序，因此完整的长文档使用train_single.py。（2）对顺序无关的超多的样本，例如包含260万篇新闻的大型训练集，在训练过程中进行random shuffle的代价是巨大的，包括shuffle的代价，重新划分training sample的代价和tokenization的代价，并且在大型训练集上我们进行预训练的轮数有限，1到2轮就能获得一个较好的预训练模型。综合考虑shuffle的代价和收益，因此也将大型训练集中的多个样本拼接为一个单一的大型文档，使用train_single.py。我们在《从头训练一个GPT2模型》一节对此进行更详细的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_on_small_file.py`：当输入的训练数据为多个样本，并且这多个样本的总体积较小时，将这些样本汇总到一个文件，每个样本占据一行，然后使用`train_on_small_file.py`。有如下两方面原因：（1）train_on_small_file.py针对每个样本建立一个单独的training sample送入Transformer Encoder中，如果一个样本的长度不足Transformer Encoder的长度（在本代码库中用n_ctx表示），那么不足部分以\\[PAD\\]来补足；超出n_ctx的部分直接截断丢弃不用。这一点和train_single.py不同，train_single.py中多个较短的样本可能会占据一个Transformer Encoder的输入长度（n_ctx）。（2）train_on_small_file.py会在不同的训练轮次中，对training samples进行random shuffle，以提高训练质量。由于train_on_small_file.py的训练数据体积较小，样本数也较小，因此每轮进行random shuffle是完全可行的。所以，如果是唐诗、宋词、现代诗、意图增强等文本数据，由于其规模较小，完全可以使用`train_on_small_file.py`来完成训练或者微调，这样得到的模型质量要高于`train_single.py`训练得到的模型。我们在《微调GPT2模型进行数据增强》一节对此进行更详细的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从头训练一个GPT2模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处我们使用一个规模较小的文件用以验证从头训练一个GPT2模型的可行性。该文件为斗破苍穹小说文本文件，规模为16MB，16万行。如下是该文件的一些基本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 weijing weijing 16M Apr  5 10:54 rawdata/train_raw.txt\n",
      "162111 rawdata/train_raw.txt\n",
      "《斗破苍穹》天蚕土豆\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何关系。\n",
      "在线阅读：http://www.shuyaya.com/read/18/\n",
      "--------------------------------------------------\n",
      "\n",
      "第一章 陨落的天才\n",
      "\n",
      "    “斗之力，三段！”\n",
      "\n",
      "    望着测验魔石碑上面闪亮得甚至有些刺眼的五个大字，少年面无表情，唇角有着一抹自嘲，紧握的手掌，因为大力，而导致略微尖锐的指甲深深的刺进了掌心之中，带来一阵阵钻心的疼痛…\n",
      "\n",
      "    “萧炎，斗之力，三段！级别：低级！”测验魔石碑之旁，一位中年男子，看了一眼碑上所显示出来的信息，语气漠然的将之公布了出来…\n",
      "\n",
      "    中年男子话刚刚脱口，便是不出意外的在人头汹涌的广场上带起了一阵嘲讽的骚动。\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; ls -laht rawdata/train_raw.txt; wc -l rawdata/train_raw.txt; head -n 15 rawdata/train_raw.txt; echo \"...\"; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没有rawdata/train_raw.txt文件，那么运行`!cd tasks/doupo; bash train.sh`，该脚本帮助建立对应文件夹并下载train_raw.txt。如下是train.sh的部分信息。首先创建raw_data文件夹，divide文件夹，tokenized文件夹，model文件夹和config文件夹。其中，raw_data文件夹用于存储原始的训练数据和进行基本预处理之后的训练数据；divide文件夹用于存储分割后的大文件（在train_single.py中有体现）；tokenized文件夹用于存储token转为数字id之后的文件；model文件夹用于储存训练好的模型；config文件夹用于储存模型的基本配置信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tasks/doupo/train.sh`的第26行用于从公网下载原始训练数据并存储到rawdata文件夹下的train_raw.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 job_dir=\"tasks/doupo\"\n",
      "2 \n",
      "3 cd ../..\n",
      "4 \n",
      "5 if [ ! -e $job_dir/rawdata ]; then\n",
      "6     mkdir $job_dir/rawdata\n",
      "7 fi\n",
      "8 \n",
      "9 if [ ! -e $job_dir/divide ]; then\n",
      "10     mkdir $job_dir/divide\n",
      "11 fi\n",
      "12 \n",
      "13 if [ ! -e $job_dir/tokenized ]; then\n",
      "14     mkdir $job_dir/tokenized\n",
      "15 fi\n",
      "16 \n",
      "17 if [ ! -e $job_dir/model ]; then\n",
      "18     mkdir $job_dir/model\n",
      "19 fi\n",
      "20 \n",
      "21 if [ ! -e $job_dir/config ]; then\n",
      "22     mkdir $job_dir/config\n",
      "23 fi\n",
      "24 \n",
      "25 if [ ! -e $job_dir/rawdata/train.txt ]; then\n",
      "26     wget -c -O $job_dir/rawdata/train_raw.txt https://github.com/GaoPeng97/transformer-xl-chinese/blob/master/data/doupo/train.txt?raw=true\n",
      "27     # remove empty lines\n",
      "28     python $job_dir/format_raw_txt.py $job_dir/rawdata/train_raw.txt $job_dir/rawdata/train.txt \n",
      "29 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=1 and $.<=29)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tasks/doupo/train.sh`的第28行调用`format_raw_txt.py`，用于移除原始文件中的空行和去除一行中左侧多余的空格(lstrip)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t'''\n",
      "     2\tThis script is used to remove empty lines in the input file \n",
      "     3\t'''\n",
      "     4\timport sys\n",
      "     5\t\n",
      "     6\tdef format(in_filename, out_filename):\n",
      "     7\t    with open(out_filename, \"w\") as fOut:\n",
      "     8\t        with open(in_filename, \"r\") as fIn:\n",
      "     9\t            for line in fIn:\n",
      "    10\t                if(line!=\"\"):\n",
      "    11\t                    fOut.write(line.lstrip())\n",
      "    12\t\n",
      "    13\t\n",
      "    14\tdef test():\n",
      "    15\t    in_filename=\"./rawdata/train_raw.txt\"\n",
      "    16\t    out_filename=\"./rawdata/train.txt\"\n",
      "    17\t    format(in_filename, out_filename)\n",
      "    18\t\n",
      "    19\t\n",
      "    20\tif __name__==\"__main__\":\n",
      "    21\t    if(len(sys.argv)<3):\n",
      "    22\t        print(\"usage: python format_raw_txt.py in_filename out_filename\")\n",
      "    23\t    else:\n",
      "    24\t        in_filename = sys.argv[1]\n",
      "    25\t        out_filename = sys.argv[2]\n",
      "    26\t        format(in_filename, out_filename)\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; cat -n format_raw_txt.py; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前多个模型都直接使用了BERT chinese字表，该字表拥有字符21128个。但是该字表有如下的问题：不包含大写字母A到Z，不包含制表符，空格等字符。我们可以将这些字符追加到BERT chinese字表之后，如`train.sh`代码中的第31行到44行所示，将新的字符表保存在doupo/config/vocab.txt文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 vocab_size=21128\n",
      "32 declare -a additional_chars=(\"“\" \"”\" \"…\" \"’\" \"‘\" \"—\" \" \" \"\\t\" \"\\`\")\n",
      "33 new_vocab_size=$(($vocab_size+${#additional_chars[@]}+26))\n",
      "34 echo 'setting config/vocab.txt and config/model_config.json'\n",
      "35 if [ ! -e $job_dir/config/vocab.txt ]; then\n",
      "36     wget -c -O $job_dir/config/vocab.txt https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt\n",
      "37     # append new characters to the vocabulary\n",
      "38     for letter in \"${additional_chars[@]}\"; do\n",
      "39         echo -e \"$letter\" >> $job_dir/config/vocab.txt\n",
      "40     done\n",
      "41     for letter in {A..Z} ; do\n",
      "42         echo $letter >> $job_dir/config/vocab.txt\n",
      "43     done\n",
      "44 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=31 and $.<=44)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以进一步的设置模型参数，并将模型参数保存于config/model_config.json。如果不存在doupo/config/model_config.json，那么doupo/train.sh的第49行拷贝config/model_config.json模板到指定位置，并进行编辑。如下的代码第52，54，56，57行用于编辑模型参数，例如将层数修改为10层，将n_ctx和n_positions从1024修改为512。因为n_ctx是Transformer Encoder能够容纳的最大序列长度，因此减半之后可以大幅度节省训练时占用的显存，同时也考虑到512是一个合理的较长的长度，能够较大限度的捕获文本上远距离的依赖关系。此外我们将stride设置为256，也就是在一个长序列上窗口大小为512，每次移动窗口的幅度为256。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 stride=256\n",
      "47 n_layers=10\n",
      "48 n_ctx=512\n",
      "49 if [ ! -e $job_dir/config/model_config.json ]; then\n",
      "50     cp config/model_config.json $job_dir/config/model_config.json\n",
      "51     # change vocabulary size\n",
      "52     perl -pi -e 's/'$vocab_size'/'$new_vocab_size'/g' $job_dir/config/model_config.json\n",
      "53     # change the number of layers from 12 to $n_layers\n",
      "54     perl -pi -e 's/\"n_layer\": 12/\"n_layer\": '$n_layers'/g' $job_dir/config/model_config.json\n",
      "55     # change the model input length from 1024 to $n_ctx\n",
      "56     perl -pi -e 's/\"n_ctx\": 1024/\"n_ctx\": '$n_ctx'/g' $job_dir/config/model_config.json\n",
      "57     perl -pi -e 's/\"n_positions\": 1024/\"n_positions\": '$n_ctx'/g' $job_dir/config/model_config.json\n",
      "58 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=46 and $.<=58)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以在`config/model_config.json`中查看即将要训练的模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t{\n",
      "     2\t  \"initializer_range\": 0.02,\n",
      "     3\t  \"layer_norm_epsilon\": 1e-05,\n",
      "     4\t  \"n_ctx\": 512,\n",
      "     5\t  \"n_embd\": 768,\n",
      "     6\t  \"n_head\": 12,\n",
      "     7\t  \"n_layer\": 10,\n",
      "     8\t  \"n_positions\": 512,\n",
      "     9\t  \"vocab_size\": 21163\n",
      "    10\t}"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; cat -n config/model_config.json; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要的数据预处理发生于`train_single.py`的`build_files`文件中，如下所示。`build_files`包含有多个参数，其中有必要说明的是`num_pieces`和`full_tokenizer`。`full_tokenizer`调用的是《Tokenization》一小节中提到的两阶段方法，效率较高。`num_pieces`将一个大文件分割为若干个小文件，以减小训练时IO一个大文件带来的内存压力。\n",
    "如下，第26行到第35行用以分割大文件到divide文件夹。分割之后，每一行补充[CLS]字符，回车符'\\\\n'转为[SEP]字符，然后调用`full_tokenizer`将token转为id。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举例来说，\"《斗破苍穹》天蚕土豆\"这一行转为\"[CLS]《斗破苍穹》天蚕土豆[SEP]\"并转为对应的数字id。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 def build_files(raw_data_path, divide_path, tokenized_data_path, full_tokenizer, num_pieces):\n",
      "19     if not os.path.exists(tokenized_data_path):\n",
      "20         os.mkdir(tokenized_data_path)\n",
      "21     if not os.path.exists(divide_path):\n",
      "22         os.mkdir(divide_path)\n",
      "23     print(\"now time: \", datetime.now())\n",
      "24     print(\"begin to divide raw text ...\")\n",
      "25 \n",
      "26     writers = [open(divide_path + 'divide_piece_{}.txt'.format(i), 'w') for i in range(0,num_pieces)]\n",
      "27 \n",
      "28     with open(raw_data_path, 'r', encoding='utf8') as f:\n",
      "29         line_num = 0\n",
      "30         for line in f:\n",
      "31             writers[line_num % num_pieces].write(\"%s\" % line)\n",
      "32             line_num += 1\n",
      "33     \n",
      "34     for i in range(0, num_pieces):\n",
      "35         writers[i].close()\n",
      "36     \n",
      "37     print('now time: ', datetime.now())\n",
      "38     print(\"begin making tokenization ...\")\n",
      "39     files = [filename for filename in os.listdir(divide_path) if f!='.gitignore']\n",
      "40     for i, filename in enumerate(files):\n",
      "41         if(os.path.isdir(filename)):\n",
      "42             continue\n",
      "43 \n",
      "44         with open(divide_path+filename, 'r', encoding='utf8') as reader:\n",
      "45             print(\"reading file {}, now time is {}\".format(filename, datetime.now()))\n",
      "46             lines = []\n",
      "47             for line in reader:\n",
      "48                 line = line.replace('\\n', '[SEP]')\n",
      "49                 line = '[CLS]' + line\n",
      "50                 lines.append(line)\n",
      "51             \n",
      "52             single_file = ''.join(lines)\n",
      "53             single_ids = full_tokenizer.convert_tokens_to_ids(full_tokenizer._tokenize(single_file))\n",
      "54             # pdb.set_trace()\n",
      "55             with open(tokenized_data_path + 'tokenized_train_{}.txt'.format(i), 'w') as f:\n",
      "56                 for id in single_ids[:-1]:\n",
      "57                     f.write(str(id) + ' ')\n",
      "58                 f.write(str(single_ids[-1]))\n",
      "59                 f.write('\\n')\n",
      "60         print('now time: {}, tokenized tokenized_train_{}.txt'.format(datetime.now(), i))\n",
      "61 \n",
      "62     print('finish')\n"
     ]
    }
   ],
   "source": [
    "!perl -ne 'print \"$. $_\" if ($.>=18 and $.<=62)' train_single.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 确定训练过程中的其他参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在确定模型参数之后，再定义训练过程中的其他参数，如下为`tasks/doupo/train.sh`中该部分代码，这些参数包括：迭代的轮数`epochs`，训练时的`batch_size`，每隔多少轮输出一次NLL的`log_step`，以及使用哪些显卡的`device`。考虑到具体的硬件资源，此处使用两块显卡——0号和1号，以及设置batch size为32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 raw_data_path=$job_dir/rawdata/train.txt\n",
      "61 tokenizer_path=$job_dir/config/vocab.txt\n",
      "62 tokenized_data_path=$job_dir/tokenized/\n",
      "63 divide_path=$job_dir/divide/\n",
      "64 model_config=$job_dir/config/model_config.json\n",
      "65 epochs=30\n",
      "66 batch_size=32\n",
      "67 log_step=100\n",
      "68 output_dir=$job_dir/model/\n",
      "69 num_pieces=1\n",
      "70 \n",
      "71 if [ ! -e $job_dir/tokenized/tokenized_train_0.txt ]; then\n",
      "72     # tokenization then run the training\n",
      "73     python train_single.py \\\n",
      "74         --raw_data_path $raw_data_path \\\n",
      "75         --tokenizer_path $tokenizer_path \\\n",
      "76         --tokenized_data_path $tokenized_data_path \\\n",
      "77         --divide_path $divide_path \\\n",
      "78         --model_config $model_config \\\n",
      "79         --epochs $epochs \\\n",
      "80         --batch_size $batch_size \\\n",
      "81         --stride $stride \\\n",
      "82         --log_step $log_step \\\n",
      "83         --output_dir $output_dir \\\n",
      "84         --num_pieces $num_pieces \\\n",
      "85         --raw \\\n",
      "86         --ignore_intermediate_epoch_model\n",
      "87 else\n",
      "88     # run the training on the tokenized files\n",
      "89     python train_single.py \\\n",
      "90         --raw_data_path $raw_data_path \\\n",
      "91         --tokenizer_path $tokenizer_path \\\n",
      "92         --tokenized_data_path $tokenized_data_path \\\n",
      "93         --divide_path $divide_path \\\n",
      "94         --model_config $model_config \\\n",
      "95         --epochs $epochs \\\n",
      "96         --batch_size $batch_size \\\n",
      "97         --stride $stride \\\n",
      "98         --log_step $log_step \\\n",
      "99         --output_dir $output_dir \\\n",
      "100         --num_pieces $num_pieces \\\n",
      "101         --device 0,1 \\\n",
      "102         --ignore_intermediate_epoch_model\n",
      "103 fi\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; perl -ne 'print \"$. $_\" if ($.>=60 and $.<=103)' train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定完毕模型参数和训练过程中的其他参数之后，可以进入到tasks/doupo文件夹，然后运行train.sh。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting config/vocab.txt and config/model_config.json\n",
      "I0416 01:14:42.333565 140639139563328 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "args:\n",
      "Namespace(batch_size=32, device='0,1', divide_path='tasks/doupo/divide/', epochs=30, fp16=False, fp16_opt_level='O1', gradient_accumulation=1, ignore_intermediate_epoch_model=True, log_step=100, lr=0.00015, max_grad_norm=1.0, model_config='tasks/doupo/config/model_config.json', num_pieces=1, output_dir='tasks/doupo/model/', pretrained_model='', raw=False, raw_data_path='tasks/doupo/rawdata/train.txt', segment=False, stride=256, tokenized_data_path='tasks/doupo/tokenized/', tokenizer_path='tasks/doupo/config/vocab.txt', warmup_steps=2000)\n",
      "config:\n",
      "{\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "using device: cuda\n",
      "calculating total steps\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "total steps = 19625\n",
      "Let's use 2 GPUs!\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:26: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "starting training\n",
      "epoch 1\n",
      "time: 2020-04-16 01:14:48.601299\n",
      "/home/weijing/.conda/envs/weijing-torch/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "now time: 1:17. Step 100 of piece 0 of epoch 1, loss 9.202316961288453\n",
      "now time: 1:19. Step 200 of piece 0 of epoch 1, loss 7.707304573059082\n",
      "now time: 1:21. Step 300 of piece 0 of epoch 1, loss 6.231863975524902\n",
      "now time: 1:24. Step 400 of piece 0 of epoch 1, loss 5.415362277030945\n",
      "now time: 1:26. Step 500 of piece 0 of epoch 1, loss 4.971680083274841\n",
      "now time: 1:28. Step 600 of piece 0 of epoch 1, loss 4.667091364860535\n",
      "epoch 2\n",
      "time: 2020-04-16 01:30:03.152946\n",
      "now time: 1:32. Step 100 of piece 0 of epoch 2, loss 6.789287486076355\n",
      "now time: 1:34. Step 200 of piece 0 of epoch 2, loss 4.226721558570862\n",
      "now time: 1:37. Step 300 of piece 0 of epoch 2, loss 4.118758888244629\n",
      "now time: 1:39. Step 400 of piece 0 of epoch 2, loss 4.030298998355866\n",
      "now time: 1:41. Step 500 of piece 0 of epoch 2, loss 3.9456340169906614\n",
      "now time: 1:44. Step 600 of piece 0 of epoch 2, loss 3.8575130224227907\n",
      "epoch 3\n",
      "time: 2020-04-16 01:45:20.002546\n",
      "now time: 1:47. Step 100 of piece 0 of epoch 3, loss 5.745515451431275\n",
      "now time: 1:50. Step 200 of piece 0 of epoch 3, loss 3.6111994218826293\n",
      "now time: 1:52. Step 300 of piece 0 of epoch 3, loss 3.532945084571838\n",
      "now time: 1:54. Step 400 of piece 0 of epoch 3, loss 3.4371526789665223\n",
      "now time: 1:57. Step 500 of piece 0 of epoch 3, loss 3.349661066532135\n",
      "now time: 1:59. Step 600 of piece 0 of epoch 3, loss 3.2717025208473207\n",
      "epoch 4\n",
      "time: 2020-04-16 02:00:35.686268\n",
      "now time: 2:2. Step 100 of piece 0 of epoch 4, loss 4.848652067184449\n",
      "now time: 2:5. Step 200 of piece 0 of epoch 4, loss 3.0546720480918883\n",
      "now time: 2:7. Step 300 of piece 0 of epoch 4, loss 2.9983620500564574\n",
      "now time: 2:9. Step 400 of piece 0 of epoch 4, loss 2.9415189242362976\n",
      "now time: 2:12. Step 500 of piece 0 of epoch 4, loss 2.8896154952049256\n",
      "now time: 2:14. Step 600 of piece 0 of epoch 4, loss 2.853637628555298\n",
      "epoch 5\n",
      "time: 2020-04-16 02:15:52.982696\n",
      "now time: 2:18. Step 100 of piece 0 of epoch 5, loss 4.237938556671143\n",
      "now time: 2:20. Step 200 of piece 0 of epoch 5, loss 2.69880491733551\n",
      "now time: 2:22. Step 300 of piece 0 of epoch 5, loss 2.6723411226272584\n",
      "now time: 2:25. Step 400 of piece 0 of epoch 5, loss 2.6393399143218996\n",
      "now time: 2:27. Step 500 of piece 0 of epoch 5, loss 2.61063467502594\n",
      "now time: 2:29. Step 600 of piece 0 of epoch 5, loss 2.590463788509369\n",
      "epoch 6\n",
      "time: 2020-04-16 02:31:08.000836\n",
      "now time: 2:33. Step 100 of piece 0 of epoch 6, loss 3.8711335635185242\n",
      "now time: 2:35. Step 200 of piece 0 of epoch 6, loss 2.4737066078186034\n",
      "now time: 2:38. Step 300 of piece 0 of epoch 6, loss 2.4557159829139708\n",
      "now time: 2:40. Step 400 of piece 0 of epoch 6, loss 2.4382388758659364\n",
      "now time: 2:42. Step 500 of piece 0 of epoch 6, loss 2.421723482608795\n",
      "now time: 2:45. Step 600 of piece 0 of epoch 6, loss 2.3982063722610474\n",
      "epoch 7\n",
      "time: 2020-04-16 02:46:22.395491\n",
      "now time: 2:48. Step 100 of piece 0 of epoch 7, loss 3.5847596406936644\n",
      "now time: 2:51. Step 200 of piece 0 of epoch 7, loss 2.2856746673583985\n",
      "now time: 2:53. Step 300 of piece 0 of epoch 7, loss 2.2785504913330077\n",
      "now time: 2:55. Step 400 of piece 0 of epoch 7, loss 2.2767979526519775\n",
      "now time: 2:58. Step 500 of piece 0 of epoch 7, loss 2.2672856426239014\n",
      "now time: 3:0. Step 600 of piece 0 of epoch 7, loss 2.2545839881896974\n",
      "epoch 8\n",
      "time: 2020-04-16 03:01:38.067122\n",
      "now time: 3:3. Step 100 of piece 0 of epoch 8, loss 3.352515172958374\n",
      "now time: 3:6. Step 200 of piece 0 of epoch 8, loss 2.1405993843078615\n",
      "now time: 3:8. Step 300 of piece 0 of epoch 8, loss 2.1453472924232484\n",
      "now time: 3:10. Step 400 of piece 0 of epoch 8, loss 2.1394610095024107\n",
      "now time: 3:13. Step 500 of piece 0 of epoch 8, loss 2.124991798400879\n",
      "now time: 3:15. Step 600 of piece 0 of epoch 8, loss 2.1123932445049287\n",
      "epoch 9\n",
      "time: 2020-04-16 03:16:51.998176\n",
      "now time: 3:19. Step 100 of piece 0 of epoch 9, loss 3.136663844585419\n",
      "now time: 3:21. Step 200 of piece 0 of epoch 9, loss 2.004424078464508\n",
      "now time: 3:23. Step 300 of piece 0 of epoch 9, loss 2.0003432142734527\n",
      "now time: 3:26. Step 400 of piece 0 of epoch 9, loss 2.0081939208507538\n",
      "now time: 3:28. Step 500 of piece 0 of epoch 9, loss 1.9936890637874602\n",
      "now time: 3:30. Step 600 of piece 0 of epoch 9, loss 1.9920781135559082\n",
      "epoch 10\n",
      "time: 2020-04-16 03:32:05.659645\n",
      "now time: 3:34. Step 100 of piece 0 of epoch 10, loss 2.9409005546569826\n",
      "now time: 3:36. Step 200 of piece 0 of epoch 10, loss 1.873287514448166\n",
      "now time: 3:39. Step 300 of piece 0 of epoch 10, loss 1.8740946745872498\n",
      "now time: 3:41. Step 400 of piece 0 of epoch 10, loss 1.8776152431964874\n",
      "now time: 3:43. Step 500 of piece 0 of epoch 10, loss 1.8794782698154449\n",
      "now time: 3:46. Step 600 of piece 0 of epoch 10, loss 1.8748361718654634\n",
      "epoch 11\n",
      "time: 2020-04-16 03:47:19.714032\n",
      "now time: 3:49. Step 100 of piece 0 of epoch 11, loss 2.7505292212963104\n",
      "now time: 3:51. Step 200 of piece 0 of epoch 11, loss 1.7488766956329345\n",
      "now time: 3:54. Step 300 of piece 0 of epoch 11, loss 1.7564728021621705\n",
      "now time: 3:56. Step 400 of piece 0 of epoch 11, loss 1.7629074132442475\n",
      "now time: 3:58. Step 500 of piece 0 of epoch 11, loss 1.7594583714008332\n",
      "now time: 4:1. Step 600 of piece 0 of epoch 11, loss 1.7469587874412538\n",
      "epoch 12\n",
      "time: 2020-04-16 04:02:33.384908\n",
      "now time: 4:4. Step 100 of piece 0 of epoch 12, loss 2.5669286179542543\n",
      "now time: 4:7. Step 200 of piece 0 of epoch 12, loss 1.6365967988967896\n",
      "now time: 4:9. Step 300 of piece 0 of epoch 12, loss 1.6398653757572175\n",
      "now time: 4:11. Step 400 of piece 0 of epoch 12, loss 1.6442046630382539\n",
      "now time: 4:14. Step 500 of piece 0 of epoch 12, loss 1.642245318889618\n",
      "now time: 4:16. Step 600 of piece 0 of epoch 12, loss 1.6417443752288818\n",
      "epoch 13\n",
      "time: 2020-04-16 04:17:44.574765\n",
      "now time: 4:20. Step 100 of piece 0 of epoch 13, loss 2.4030781209468843\n",
      "now time: 4:22. Step 200 of piece 0 of epoch 13, loss 1.5256192553043366\n",
      "now time: 4:24. Step 300 of piece 0 of epoch 13, loss 1.5365435802936553\n",
      "now time: 4:27. Step 400 of piece 0 of epoch 13, loss 1.5389688789844513\n",
      "now time: 4:29. Step 500 of piece 0 of epoch 13, loss 1.5388435673713685\n",
      "now time: 4:31. Step 600 of piece 0 of epoch 13, loss 1.537399308681488\n",
      "epoch 14\n",
      "time: 2020-04-16 04:32:55.731805\n",
      "now time: 4:35. Step 100 of piece 0 of epoch 14, loss 2.245744732618332\n",
      "now time: 4:37. Step 200 of piece 0 of epoch 14, loss 1.4283682191371918\n",
      "now time: 4:39. Step 300 of piece 0 of epoch 14, loss 1.439707955121994\n",
      "now time: 4:42. Step 400 of piece 0 of epoch 14, loss 1.4385538804531097\n",
      "now time: 4:44. Step 500 of piece 0 of epoch 14, loss 1.4388358771800995\n",
      "now time: 4:46. Step 600 of piece 0 of epoch 14, loss 1.4463050270080566\n",
      "epoch 15\n",
      "time: 2020-04-16 04:48:07.590364\n",
      "now time: 4:50. Step 100 of piece 0 of epoch 15, loss 2.1014110934734345\n",
      "now time: 4:52. Step 200 of piece 0 of epoch 15, loss 1.3430095541477203\n",
      "now time: 4:55. Step 300 of piece 0 of epoch 15, loss 1.3440466809272766\n",
      "now time: 4:57. Step 400 of piece 0 of epoch 15, loss 1.3469557309150695\n",
      "now time: 4:59. Step 500 of piece 0 of epoch 15, loss 1.3533795082569122\n",
      "now time: 5:2. Step 600 of piece 0 of epoch 15, loss 1.350544846057892\n",
      "epoch 16\n",
      "time: 2020-04-16 05:03:21.359050\n",
      "now time: 5:5. Step 100 of piece 0 of epoch 16, loss 1.9660143125057221\n",
      "now time: 5:8. Step 200 of piece 0 of epoch 16, loss 1.2541267347335816\n",
      "now time: 5:10. Step 300 of piece 0 of epoch 16, loss 1.259226269721985\n",
      "now time: 5:12. Step 400 of piece 0 of epoch 16, loss 1.2658753824234008\n",
      "now time: 5:14. Step 500 of piece 0 of epoch 16, loss 1.2690154457092284\n",
      "now time: 5:17. Step 600 of piece 0 of epoch 16, loss 1.2719350898265838\n",
      "epoch 17\n",
      "time: 2020-04-16 05:18:33.537657\n",
      "now time: 5:20. Step 100 of piece 0 of epoch 17, loss 1.8483317708969116\n",
      "now time: 5:23. Step 200 of piece 0 of epoch 17, loss 1.1701875877380372\n",
      "now time: 5:25. Step 300 of piece 0 of epoch 17, loss 1.1864917719364165\n",
      "now time: 5:27. Step 400 of piece 0 of epoch 17, loss 1.1902322900295257\n",
      "now time: 5:30. Step 500 of piece 0 of epoch 17, loss 1.191501111984253\n",
      "now time: 5:32. Step 600 of piece 0 of epoch 17, loss 1.1947383069992066\n",
      "epoch 18\n",
      "time: 2020-04-16 05:33:44.124617\n",
      "now time: 5:36. Step 100 of piece 0 of epoch 18, loss 1.7342723166942597\n",
      "now time: 5:38. Step 200 of piece 0 of epoch 18, loss 1.1028614771366119\n",
      "now time: 5:40. Step 300 of piece 0 of epoch 18, loss 1.109117056131363\n",
      "now time: 5:43. Step 400 of piece 0 of epoch 18, loss 1.118437031507492\n",
      "now time: 5:45. Step 500 of piece 0 of epoch 18, loss 1.1209260213375092\n",
      "now time: 5:47. Step 600 of piece 0 of epoch 18, loss 1.124591029882431\n",
      "epoch 19\n",
      "time: 2020-04-16 05:48:56.031032\n",
      "now time: 5:51. Step 100 of piece 0 of epoch 19, loss 1.6284554076194764\n",
      "now time: 5:53. Step 200 of piece 0 of epoch 19, loss 1.0364246493577958\n",
      "now time: 5:55. Step 300 of piece 0 of epoch 19, loss 1.0447640657424926\n",
      "now time: 5:58. Step 400 of piece 0 of epoch 19, loss 1.0529798078536987\n",
      "now time: 6:0. Step 500 of piece 0 of epoch 19, loss 1.0552983176708222\n",
      "now time: 6:2. Step 600 of piece 0 of epoch 19, loss 1.0555978977680207\n",
      "epoch 20\n",
      "time: 2020-04-16 06:04:08.537717\n",
      "now time: 6:6. Step 100 of piece 0 of epoch 20, loss 1.5358845353126527\n",
      "now time: 6:8. Step 200 of piece 0 of epoch 20, loss 0.9747134763002395\n",
      "now time: 6:11. Step 300 of piece 0 of epoch 20, loss 0.9841806548833847\n",
      "now time: 6:13. Step 400 of piece 0 of epoch 20, loss 0.9879507029056549\n",
      "now time: 6:15. Step 500 of piece 0 of epoch 20, loss 0.9952266401052475\n",
      "now time: 6:18. Step 600 of piece 0 of epoch 20, loss 0.9997190886735916\n",
      "epoch 21\n",
      "time: 2020-04-16 06:19:19.802103\n",
      "now time: 6:21. Step 100 of piece 0 of epoch 21, loss 1.4491075098514556\n",
      "now time: 6:23. Step 200 of piece 0 of epoch 21, loss 0.9256779366731643\n",
      "now time: 6:26. Step 300 of piece 0 of epoch 21, loss 0.9296008312702179\n",
      "now time: 6:28. Step 400 of piece 0 of epoch 21, loss 0.9329792124032974\n",
      "now time: 6:30. Step 500 of piece 0 of epoch 21, loss 0.9387668401002884\n",
      "now time: 6:33. Step 600 of piece 0 of epoch 21, loss 0.9413994669914245\n",
      "epoch 22\n",
      "time: 2020-04-16 06:34:32.006479\n",
      "now time: 6:36. Step 100 of piece 0 of epoch 22, loss 1.369708793759346\n",
      "now time: 6:39. Step 200 of piece 0 of epoch 22, loss 0.8698766320943833\n",
      "now time: 6:41. Step 300 of piece 0 of epoch 22, loss 0.879535500407219\n",
      "now time: 6:43. Step 400 of piece 0 of epoch 22, loss 0.882276793718338\n",
      "now time: 6:46. Step 500 of piece 0 of epoch 22, loss 0.8877784383296966\n",
      "now time: 6:48. Step 600 of piece 0 of epoch 22, loss 0.8892823547124863\n",
      "epoch 23\n",
      "time: 2020-04-16 06:49:43.700830\n",
      "now time: 6:52. Step 100 of piece 0 of epoch 23, loss 1.3021733957529067\n",
      "now time: 6:54. Step 200 of piece 0 of epoch 23, loss 0.8236924302577973\n",
      "now time: 6:56. Step 300 of piece 0 of epoch 23, loss 0.835443131327629\n",
      "now time: 6:59. Step 400 of piece 0 of epoch 23, loss 0.8385501962900161\n",
      "now time: 7:1. Step 500 of piece 0 of epoch 23, loss 0.8440354722738266\n",
      "now time: 7:3. Step 600 of piece 0 of epoch 23, loss 0.8432110524177552\n",
      "epoch 24\n",
      "time: 2020-04-16 07:04:55.318724\n",
      "now time: 7:7. Step 100 of piece 0 of epoch 24, loss 1.23594005048275\n",
      "now time: 7:9. Step 200 of piece 0 of epoch 24, loss 0.784839220046997\n",
      "now time: 7:11. Step 300 of piece 0 of epoch 24, loss 0.795030711889267\n",
      "now time: 7:14. Step 400 of piece 0 of epoch 24, loss 0.7949240291118622\n",
      "now time: 7:16. Step 500 of piece 0 of epoch 24, loss 0.7992287290096283\n",
      "now time: 7:18. Step 600 of piece 0 of epoch 24, loss 0.8026183515787124\n",
      "epoch 25\n",
      "time: 2020-04-16 07:20:06.546957\n",
      "now time: 7:22. Step 100 of piece 0 of epoch 25, loss 1.1748134887218475\n",
      "now time: 7:24. Step 200 of piece 0 of epoch 25, loss 0.7487787473201751\n",
      "now time: 7:27. Step 300 of piece 0 of epoch 25, loss 0.7541225963830948\n",
      "now time: 7:29. Step 400 of piece 0 of epoch 25, loss 0.7591692370176315\n",
      "now time: 7:31. Step 500 of piece 0 of epoch 25, loss 0.7653062713146209\n",
      "now time: 7:34. Step 600 of piece 0 of epoch 25, loss 0.7620276564359665\n",
      "epoch 26\n",
      "time: 2020-04-16 07:35:15.116928\n",
      "now time: 7:37. Step 100 of piece 0 of epoch 26, loss 1.1271157205104827\n",
      "now time: 7:39. Step 200 of piece 0 of epoch 26, loss 0.7196405810117722\n",
      "now time: 7:42. Step 300 of piece 0 of epoch 26, loss 0.7242998188734054\n",
      "now time: 7:44. Step 400 of piece 0 of epoch 26, loss 0.725955114364624\n",
      "now time: 7:46. Step 500 of piece 0 of epoch 26, loss 0.725811847448349\n",
      "now time: 7:49. Step 600 of piece 0 of epoch 26, loss 0.7297996699810028\n",
      "epoch 27\n",
      "time: 2020-04-16 07:50:25.795469\n",
      "now time: 7:52. Step 100 of piece 0 of epoch 27, loss 1.07976269364357\n",
      "now time: 7:55. Step 200 of piece 0 of epoch 27, loss 0.6927031743526458\n",
      "now time: 7:57. Step 300 of piece 0 of epoch 27, loss 0.6950196087360382\n",
      "now time: 7:59. Step 400 of piece 0 of epoch 27, loss 0.6976888173818588\n",
      "now time: 8:2. Step 500 of piece 0 of epoch 27, loss 0.6997041636705399\n",
      "now time: 8:4. Step 600 of piece 0 of epoch 27, loss 0.6983793312311173\n",
      "epoch 28\n",
      "time: 2020-04-16 08:05:36.768842\n",
      "now time: 8:7. Step 100 of piece 0 of epoch 28, loss 1.041203372478485\n",
      "now time: 8:10. Step 200 of piece 0 of epoch 28, loss 0.6684932935237885\n",
      "now time: 8:12. Step 300 of piece 0 of epoch 28, loss 0.6704179030656815\n",
      "now time: 8:14. Step 400 of piece 0 of epoch 28, loss 0.6714022094011307\n",
      "now time: 8:17. Step 500 of piece 0 of epoch 28, loss 0.6705535060167312\n",
      "now time: 8:19. Step 600 of piece 0 of epoch 28, loss 0.6737305068969727\n",
      "epoch 29\n",
      "time: 2020-04-16 08:20:47.409262\n",
      "now time: 8:23. Step 100 of piece 0 of epoch 29, loss 1.0074528831243514\n",
      "now time: 8:25. Step 200 of piece 0 of epoch 29, loss 0.648998013138771\n",
      "now time: 8:27. Step 300 of piece 0 of epoch 29, loss 0.6515571510791779\n",
      "now time: 8:30. Step 400 of piece 0 of epoch 29, loss 0.6512559533119202\n",
      "now time: 8:32. Step 500 of piece 0 of epoch 29, loss 0.652387506365776\n",
      "now time: 8:34. Step 600 of piece 0 of epoch 29, loss 0.6522213840484619\n",
      "epoch 30\n",
      "time: 2020-04-16 08:35:58.999761\n",
      "now time: 8:38. Step 100 of piece 0 of epoch 30, loss 0.986364706158638\n",
      "now time: 8:40. Step 200 of piece 0 of epoch 30, loss 0.6341836673021316\n",
      "now time: 8:42. Step 300 of piece 0 of epoch 30, loss 0.6344272303581238\n",
      "now time: 8:45. Step 400 of piece 0 of epoch 30, loss 0.635601818561554\n",
      "now time: 8:47. Step 500 of piece 0 of epoch 30, loss 0.6358217197656632\n",
      "now time: 8:49. Step 600 of piece 0 of epoch 30, loss 0.6335765486955642\n",
      "training finished\n",
      "I0416 08:51:11.429557 140639139563328 configuration_utils.py:71] Configuration saved in tasks/doupo/model/final_model/config.json\n",
      "I0416 08:51:12.115916 140639139563328 modeling_utils.py:205] Model weights saved in tasks/doupo/model/final_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo; bash train.sh; cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型保存于`tasks/doupo/model/final_model`中，该文件夹下有两个文件，`config.json`，`pytorch_model.bin`。在`config.json`中包含了模型的基本参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 344M\n",
      "-rw-rw-r--  1 weijing weijing 344M Apr 16 08:51 pytorch_model.bin\n",
      "-rw-rw-r--  1 weijing weijing  596 Apr 16 08:51 config.json\n",
      "drwxrwxr-x  2 weijing weijing 4.0K Mar 31 06:32 .\n",
      "drwxrwxr-x 33 weijing weijing 4.0K Mar 31 06:32 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -laht tasks/doupo/model/final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch_model.bin`可以被直接加载，并能够输出模型结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 10:41:52.995795 140436257081152 configuration_utils.py:148] loading configuration file tasks/doupo/model/final_model/config.json\n",
      "I0416 10:41:52.998218 140436257081152 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "I0416 10:41:52.999756 140436257081152 modeling_utils.py:334] loading weights file tasks/doupo/model/final_model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(21163, 768)\n",
      "    (wpe): Embedding(512, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=21163, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained(\"tasks/doupo/model/final_model\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要查看模型中的参数个数，可以使用如下命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in the model is 87526656\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"The number of parameters in the model is %s\" % pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在训练好的模型上做Inference，生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate.py`脚本使用top-k sampling生成文本。`tasks/doupo/generate.sh`定义了top-k sampling的参数，如下所示，topk=50，nsamples=10，temperature=0.8，length=18，prefix=[SEP][CLS]萧炎。topk越小，多样性越低。temperature $T$也定义了多样性：取到词表中第i个词的概率由logits向量$z_{1:V}$和温度T决定, $q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$。具体的，T越大，向量$z_{1:V}$中各分量的绝对值就越趋向于0，造成多样性提高而采样质量下降；T越小，则各分量就越远离0，多样性下降而质量提升。一般的，top-k sampling中使用的T为0.8。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tjob_dir=\"tasks/doupo\"\n",
      "     2\t\n",
      "     3\tcd ../..\n",
      "     4\t\n",
      "     5\tif [ ! -e $job_dir/outputs ]; then\n",
      "     6\t    mkdir $job_dir/outputs\n",
      "     7\tfi\n",
      "     8\t\n",
      "     9\tpython generate.py \\\n",
      "    10\t    --device 0 \\\n",
      "    11\t    --model_path $job_dir/model/final_model/ \\\n",
      "    12\t    --model_config $job_dir/model/final_model/model_config.json \\\n",
      "    13\t    --tokenizer_path $job_dir/config/vocab.txt \\\n",
      "    14\t    --temperature 0.8 \\\n",
      "    15\t    --prefix [SEP][CLS]萧炎 \\\n",
      "    16\t    --length 100 \\\n",
      "    17\t    --topk 50 \\\n",
      "    18\t    --nsamples 10 \\\n",
      "    19\t    --save_samples \\\n",
      "    20\t    --save_samples_path $job_dir/outputs/\n"
     ]
    }
   ],
   "source": [
    "!cat -n tasks/doupo/generate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0416 09:33:09.533224 139695085782848 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "args:\n",
      "Namespace(batch_size=1, device='0', fast_pattern=False, length=100, model_config='tasks/doupo/model/final_model/model_config.json', model_path='tasks/doupo/model/final_model/', no_wordpiece=False, nsamples=10, prefix='[SEP][CLS]萧炎', repetition_penalty=1.0, save_samples=True, save_samples_path='tasks/doupo/outputs/', segment=False, temperature=0.8, tokenizer_path='tasks/doupo/config/vocab.txt', topk=50, topp=0)\n",
      "I0416 09:33:09.818720 139695085782848 configuration_utils.py:148] loading configuration file tasks/doupo/model/final_model/config.json\n",
      "I0416 09:33:09.819159 139695085782848 configuration_utils.py:168] Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 512,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 10,\n",
      "  \"n_positions\": 512,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21163\n",
      "}\n",
      "\n",
      "I0416 09:33:09.819901 139695085782848 modeling_utils.py:334] loading weights file tasks/doupo/model/final_model/pytorch_model.bin\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 142.36it/s]\n",
      "======================================== SAMPLE 1 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎目光平淡的望着那些闪掠而来的黑影，从纳戒中取出一块玉牌，玉牌之上，隐隐间渗透着一丝诡异紫色火焰。[SEP][CLS]那些细小的火焰缓缓飘荡在伤疤之上，整个房间之中，都是泛着一点点的光泽。[SEP][CLS]萧炎目光眨也不眨的盯着玉牌\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 144.02it/s]\n",
      "======================================== SAMPLE 2 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎微微点头，他并没有与魂殿有太大的恩怨，既然如此，也只能将这两次的麻烦解决。[SEP][CLS]“既然如此，那便现身，若是再留意的话，或许便是可以试试能否将你二人请到与菩提化体涎交予我。”[SEP][CLS]见到萧炎并未在意，丹塔老祖\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.70it/s]\n",
      "======================================== SAMPLE 3 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎手掌刚刚握下“天妖凰族的王八蛋”[SEP][CLS]心头松了一口气，眼中也是掠过一抹凝重，果然是名不虚传冉雨的斗技，而且还是真正的王族血脉，这等存在，方才是真正的血脉，在萧炎手中，也是真正的能够竞得上天妖凰族。[SEP][CLS]“\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.62it/s]\n",
      "======================================== SAMPLE 4 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎面色凝重，这种时候，他也是首次选择了手脚，未曾料到，这一次，是他的竞争对手，以前的速度虽略微有些狼狈，但也是完全不是他所希望的，当下只能一咬牙，速度急忙加快。[SEP][CLS]在萧炎加入掉曹颖与丹轩之前，曹颖，宋清\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.68it/s]\n",
      "======================================== SAMPLE 5 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的身形，在无数道震惊目光注视中，直接是诡异消失[SEP][CLS]原本高达几十米的北方天际之上，一闪间，便是消失在了天际之边。[SEP][CLS]“嘭！”[SEP][CLS]翎泉脚掌刚刚落地，一道低沉闷响突然自城外传来，旋即一道身影从城市之外暴掠而\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 146.10it/s]\n",
      "======================================== SAMPLE 6 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的目光，忽然转向一旁的石台，那里，一位身穿白衣的青年，正脸带微笑的缓缓走来，在他的面前，摆放着一个小袋，笑眯眯的望着他。[SEP][CLS]“这位老先生，如果您所说的是他的体内火毒，这些小女孩的体内正统，而且还全部都\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 139.50it/s]\n",
      "======================================== SAMPLE 7 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎笑了笑，也不在这个话题上继续纠缠，拱手道：“多谢姚坊主帮忙，今天的事，交给我便好。”[SEP][CLS]“姚坊主，我来此处，是你自己介绍的地方，多加我与大哥让得你再次共享这换丹药的资格。”见到萧炎摇头，那姚坊主却是摆\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 134.48it/s]\n",
      "======================================== SAMPLE 8 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎手掌轻轻碰撞，这股巨大的暗劲风涟漪，犹如涟漪一般，从那乱石堆中扩散而出，一时间，这片混乱战场，便是陷入了混乱的战场中。[SEP][CLS]广场边缘处，薰儿纤手一开飘落额前的青丝，淡淡的声音，在全场回荡着：“没想到这妮\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 134.20it/s]\n",
      "======================================== SAMPLE 9 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎的目光，并未因为那黑甲身影的半点而有所停留，他的目光，死死的锁定着那不断蠕动的身体，但其他的那种熟悉，却是令得他的灵魂都是有种被绞碎的感觉，他明白，这是灵魂的主人！[SEP][CLS]“是灵魂力量体？”[SEP][CLS]萧炎的灵魂\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 133.47it/s]\n",
      "======================================== SAMPLE 10 ========================================\n",
      "\n",
      "[SEP][CLS]萧炎笑了笑，也不说话，直接将话题转移到了最为激烈的大厅，笑吟吟的宣布着打滚的地方，今天的事，照旧围确是萧家的后辈，日后他们再次为萧家做了嫁衣，照料她回复了家族在加玛帝国的地位，日后若是还有机会，也尽数去抓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!cd tasks/doupo;bash generate.sh;cd ../..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述文本生成结果保存于`tasks/doupo/generate.sh`中定义的`$save_samples_path`文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调GPT2模型进行数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
